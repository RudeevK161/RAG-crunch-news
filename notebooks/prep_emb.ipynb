{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14561731,"sourceType":"datasetVersion","datasetId":9301146},{"sourceId":14584413,"sourceType":"datasetVersion","datasetId":9316141}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Новый подход","metadata":{}},{"cell_type":"code","source":"from abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Optional, Union, Generator\nimport numpy as np\nfrom scipy.sparse import csr_matrix, csc_matrix, save_npz, load_npz\nimport json\nimport pickle\nfrom pathlib import Path\nimport psutil\nimport os\nimport gc\nimport time\nfrom dataclasses import dataclass\nimport warnings\nimport re\nfrom sklearn.preprocessing import normalize\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\nwarnings.filterwarnings('ignore')\n\n\ndef clean_text_for_embedding(text):\n    \"\"\"\n    Быстрая чистка текста для эмбеддингов\n    \"\"\"\n    if not isinstance(text, str):\n        return \"\"\n    \n    text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\S+', '', text, flags=re.MULTILINE)\n    \n    text = re.sub(r'\\(\\d+\\)', '', text)\n\n    text = re.sub(r'Subscribe to.*casts\\.', '', text, flags=re.DOTALL)\n    text = re.sub(r'Listen to.*episode.*:', '', text, flags=re.DOTALL)\n    text = re.sub(r'You also can follow.*@\\w+', '', text)\n    \n    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n    text = re.sub(r'\\n+', ' ', text)\n    \n    text = ' '.join(text.split())\n    \n    return text.strip()\n\n\n@dataclass\nclass EmbeddingConfig:\n    \"\"\"Конфигурация для генерации эмбеддингов\"\"\"\n    batch_size: int = 32\n    use_mmap: bool = True  \n    temp_dir: str = \"./temp_embeddings\"\n    max_memory_gb: float = 4.0  \n    dtype: str = \"float32\"\n\nclass BaseEmbeddingGenerator(ABC):\n    \"\"\"Базовый абстрактный класс для генераторов эмбеддингов\"\"\"\n    \n    def __init__(self, config: EmbeddingConfig = None):\n        self.config = config or EmbeddingConfig()\n        Path(self.config.temp_dir).mkdir(parents=True, exist_ok=True)\n        \n    @abstractmethod\n    def fit(self, texts: List[str]) -> 'BaseEmbeddingGenerator':\n        \"\"\"Обучение модели на текстах\"\"\"\n        pass\n    \n    @abstractmethod\n    def transform(self, texts: List[str]) -> Union[np.ndarray, csr_matrix]:\n        \"\"\"Преобразование текстов в эмбеддинги\"\"\"\n        pass\n    \n    @abstractmethod\n    def fit_transform(self, texts: List[str]) -> Union[np.ndarray, csr_matrix]:\n        \"\"\"Обучение и преобразование\"\"\"\n        pass\n    \n    def save(self, path: str) -> None:\n        \"\"\"Сохранение модели\"\"\"\n        save_path = Path(path)\n        save_path.mkdir(parents=True, exist_ok=True)\n        \n        # Сохраняем конфиг\n        config_path = save_path / \"config.json\"\n        with open(config_path, 'w') as f:\n            json.dump(self.config.__dict__, f)\n    \n    @classmethod\n    def load(cls, path: str) -> 'BaseEmbeddingGenerator':\n        \"\"\"Загрузка модели\"\"\"\n        pass\n    \n    def _check_memory_usage(self) -> bool:\n        \"\"\"Проверка использования памяти\"\"\"\n        process = psutil.Process(os.getpid())\n        memory_gb = process.memory_info().rss / 1024 / 1024 / 1024\n        \n        if memory_gb > self.config.max_memory_gb:\n            print(f\"Предупреждение: Использовано {memory_gb:.2f} GB памяти \"\n                  f\"(лимит: {self.config.max_memory_gb} GB)\")\n            return False\n        return True\n    \n    def _batch_generator(self, data: List, batch_size: int) -> Generator:\n        \"\"\"Генератор батчей\"\"\"\n        for i in range(0, len(data), batch_size):\n            yield data[i:i + batch_size]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T17:41:09.574416Z","iopub.execute_input":"2026-01-25T17:41:09.574953Z","iopub.status.idle":"2026-01-25T17:41:09.587825Z","shell.execute_reply.started":"2026-01-25T17:41:09.574929Z","shell.execute_reply":"2026-01-25T17:41:09.587100Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm.auto import tqdm\n\nclass DenseEmbeddingGenerator(BaseEmbeddingGenerator):\n    \"\"\"Генератор dense эмбеддингов\"\"\"\n    \n    def __init__(self,\n                 model_name: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n                 device: Optional[str] = None,\n                 normalize: bool = True,\n                 config: EmbeddingConfig = None):\n        super().__init__(config)\n        \n        self.model_name = model_name\n        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n        self.normalize = normalize\n        \n        self._model = None\n        self.embedding_dim = 0\n    \n    @property\n    def model(self) -> SentenceTransformer:\n        \"\"\"Ленивая загрузка модели\"\"\"\n        if self._model is None:\n            print(f\"Загрузка dense модели: {self.model_name}\")\n            \n            self._free_memory()\n            \n            self._model = SentenceTransformer(\n                self.model_name,\n                device=self.device\n            )\n            \n            test_embedding = self._model.encode([\"test\"], \n                                               convert_to_numpy=True)\n            self.embedding_dim = test_embedding.shape[1]\n            \n            print(f\"✓ Модель загружена. Размерность эмбеддингов: {self.embedding_dim}\")\n        \n        return self._model\n    \n    def _free_memory(self):\n        \"\"\"Освобождение памяти\"\"\"\n        gc.collect()\n        if self.device == 'cuda' and torch.cuda.is_available():\n            torch.cuda.empty_cache()\n    \n    def fit(self, texts: List[str]) -> 'DenseEmbeddingGenerator':\n        \"\"\"Для dense моделей fit не требуется (но нужен для интерфейса)\"\"\"\n        print(\"Dense модели не требуют обучения на данных\")\n        return self\n    \n    def transform(self, texts: List[str], \n                  save_to_file: Optional[str] = None,\n                  show_progress: bool = True) -> np.ndarray:\n        \"\"\"Преобразование текстов в dense эмбеддинги\"\"\"\n        print(f\"Генерация dense эмбеддингов для {len(texts)} текстов...\")\n        \n        if len(texts) > 50000 and self.config.use_mmap:\n            return self._transform_large_mmap(texts, save_to_file, show_progress)\n        \n        if len(texts) > 1000:\n            return self._transform_batched(texts, save_to_file, show_progress)\n        \n        return self._transform_small(texts, save_to_file, show_progress)\n    \n    def _transform_small(self, texts: List[str], \n                        save_to_file: Optional[str],\n                        show_progress: bool) -> np.ndarray:\n        \"\"\"Обработка небольших данных\"\"\"\n        embeddings = self.model.encode(\n            texts,\n            batch_size=self.config.batch_size,\n            show_progress_bar=show_progress,\n            convert_to_numpy=True,\n            normalize_embeddings=self.normalize\n        )\n        \n        if save_to_file:\n            np.save(save_to_file, embeddings)\n            print(f\"✓ Эмбеддинги сохранены в {save_to_file}\")\n        \n        return embeddings\n    \n    def _transform_batched(self, texts: List[str], \n                          save_to_file: Optional[str],\n                          show_progress: bool) -> np.ndarray:\n        \"\"\"Батчевая обработка средних данных\"\"\"\n        print(\"Используем батчевую обработку...\")\n        \n        all_embeddings = []\n        batch_size = self.config.batch_size\n        \n        if show_progress:\n            pbar = tqdm(total=len(texts), desc=\"Генерация эмбеддингов\")\n        \n        for i in range(0, len(texts), batch_size):\n            batch_texts = texts[i:i + batch_size]\n\n            batch_emb = self.model.encode(\n                batch_texts,\n                batch_size=batch_size,\n                show_progress_bar=False,\n                convert_to_numpy=True,\n                normalize_embeddings=self.normalize\n            )\n            \n            all_embeddings.append(batch_emb)\n            \n            if show_progress:\n                pbar.update(len(batch_texts))\n            \n            if i % (batch_size * 10) == 0:\n                self._check_memory_usage()\n                gc.collect()\n        \n        if show_progress:\n            pbar.close()\n\n        embeddings = np.vstack(all_embeddings)\n        \n        if save_to_file:\n            np.save(save_to_file, embeddings)\n            print(f\"✓ Эмбеддинги сохранены в {save_to_file}\")\n        \n        return embeddings\n    \n    def _transform_large_mmap(self, texts: List[str], \n                             save_to_file: Optional[str],\n                             show_progress: bool) -> np.ndarray:\n        \"\"\"Обработка очень больших данных с memory-mapped файлами\"\"\"\n        print(\"Используем memory-mapped файлы для больших данных...\")\n        \n        if not save_to_file:\n            raise ValueError(\"Для больших данных требуется указать save_to_file\")\n        \n        total_samples = len(texts)\n        mmap_file = np.memmap(\n            save_to_file,\n            dtype=self.config.dtype,\n            mode='w+',\n            shape=(total_samples, self.embedding_dim)\n        )\n        \n        batch_size = self.config.batch_size\n        \n        if show_progress:\n            pbar = tqdm(total=total_samples, desc=\"Генерация эмбеддингов\")\n        \n        for i in range(0, total_samples, batch_size):\n            batch_texts = texts[i:i + batch_size]\n            \n            batch_emb = self.model.encode(\n                batch_texts,\n                batch_size=batch_size,\n                show_progress_bar=False,\n                convert_to_numpy=True,\n                normalize_embeddings=self.normalize\n            )\n            \n            mmap_file[i:i + len(batch_texts)] = batch_emb\n            \n            if show_progress:\n                pbar.update(len(batch_texts))\n\n            del batch_emb\n            if i % (batch_size * 20) == 0:\n                self._check_memory_usage()\n                gc.collect()\n                if self.device == 'cuda':\n                    torch.cuda.empty_cache()\n        \n        if show_progress:\n            pbar.close()\n        \n        mmap_file.flush()\n        \n        print(f\"✓ Эмбеддинги сохранены в {save_to_file}\")\n\n        return np.load(save_to_file, mmap_mode='r')\n    \n    def fit_transform(self, texts: List[str], \n                     save_to_file: Optional[str] = None,\n                     show_progress: bool = True) -> np.ndarray:\n        \"\"\"Обучение и преобразование\"\"\"\n        self.fit(texts)\n        return self.transform(texts, save_to_file, show_progress)\n    \n    def save(self, path: str) -> None:\n        \"\"\"Сохранение конфигурации модели\"\"\"\n        super().save(path)\n        save_path = Path(path)\n        \n        model_info = {\n            'model_name': self.model_name,\n            'device': self.device,\n            'normalize': self.normalize,\n            'embedding_dim': self.embedding_dim\n        }\n        \n        model_info_path = save_path / \"model_info.json\"\n        with open(model_info_path, 'w') as f:\n            json.dump(model_info, f)\n    \n    @classmethod\n    def load(cls, path: str) -> 'DenseEmbeddingGenerator':\n        \"\"\"Загрузка конфигурации модели\"\"\"\n        load_path = Path(path)\n        \n        config_path = load_path / \"config.json\"\n        with open(config_path, 'r') as f:\n            config_dict = json.load(f)\n        \n        config = EmbeddingConfig(**config_dict)\n        \n        model_info_path = load_path / \"model_info.json\"\n        with open(model_info_path, 'r') as f:\n            model_info = json.load(f)\n        \n        instance = cls(\n            model_name=model_info['model_name'],\n            device=model_info['device'],\n            normalize=model_info['normalize'],\n            config=config\n        )\n        \n        instance.embedding_dim = model_info['embedding_dim']\n        \n        return instance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T18:28:35.160753Z","iopub.execute_input":"2026-01-22T18:28:35.161769Z","iopub.status.idle":"2026-01-22T18:28:35.182880Z","shell.execute_reply.started":"2026-01-22T18:28:35.161740Z","shell.execute_reply":"2026-01-22T18:28:35.182156Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class EmbeddingFactory:\n    \"\"\"Фабрика для создания и управления эмбеддингами\"\"\"\n    \n    @staticmethod\n    def create_dense_generator(config: Dict[str, Any] = None) -> DenseEmbeddingGenerator:\n        \"\"\"Создание dense генератора\"\"\"\n        default_config = {\n            'model_name': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n            'device': None,\n            'normalize': True,\n            'config': EmbeddingConfig(batch_size=32)\n        }\n        \n        if config:\n            default_config.update(config)\n        \n        return DenseEmbeddingGenerator(\n            model_name=default_config['model_name'],\n            device=default_config['device'],\n            normalize=default_config['normalize'],\n            config=default_config['config']\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T18:28:48.054800Z","iopub.execute_input":"2026-01-22T18:28:48.055410Z","iopub.status.idle":"2026-01-22T18:28:48.062344Z","shell.execute_reply.started":"2026-01-22T18:28:48.055385Z","shell.execute_reply":"2026-01-22T18:28:48.061596Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model_name = \"Qwen/Qwen3-Embedding-0.6B\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T17:44:20.616203Z","iopub.execute_input":"2026-01-22T17:44:20.616562Z","iopub.status.idle":"2026-01-22T17:44:20.620619Z","shell.execute_reply.started":"2026-01-22T17:44:20.616536Z","shell.execute_reply":"2026-01-22T17:44:20.619853Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"with open('/kaggle/input/crunch/techcrunch_ai_5488_articles_20260112_1535.json', 'r', encoding='utf-8') as f:\n    articles = json.load(f)\n\ntexts = [article['text'] for article in articles]\ntexts_clean = [clean_text_for_embedding(text) for text in texts]\nprint(f\"Загружено {len(texts)} статей\")\n\n# 'intfloat/multilingual-e5-large-instruct'\ndense_config = {\n    'model_name': model_name,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    #'device': 'cpu',\n    'config': EmbeddingConfig(\n        batch_size=2,\n        use_mmap=True,\n        max_memory_gb=4.0\n    )\n}\n\ndense_gen = EmbeddingFactory.create_dense_generator(dense_config)\ndense_file = \"/kaggle/working/dense_embeddings.npy\"\n        \ndense_embeddings = dense_gen.fit_transform(\n    texts_clean,\n    save_to_file=dense_file,\n    show_progress=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T15:07:36.891634Z","iopub.execute_input":"2026-01-22T15:07:36.892258Z","iopub.status.idle":"2026-01-22T15:35:41.815095Z","shell.execute_reply.started":"2026-01-22T15:07:36.892231Z","shell.execute_reply":"2026-01-22T15:35:41.814486Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Загружено 5488 статей\nDense модели не требуют обучения на данных\nГенерация dense эмбеддингов для 5488 текстов...\nИспользуем батчевую обработку...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Генерация эмбеддингов:   0%|          | 0/5488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e35b41673ff44519e2c0822c890d56e"}},"metadata":{}},{"name":"stdout","text":"Загрузка dense модели: Qwen/Qwen3-Embedding-0.6B\n✓ Модель загружена. Размерность эмбеддингов: 1024\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n✓ Эмбеддинги сохранены в /kaggle/working/dense_embeddings.npy\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import json\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nimport torch\nfrom typing import List, Dict, Set\nfrom sklearn.preprocessing import normalize\nfrom datetime import datetime\n\n\nwith open('/kaggle/input/crunch/techcrunch_ai_5488_articles_20260112_1535.json', 'r', encoding='utf-8') as f:\n    articles = json.load(f)\nprint(f\"Статей: {len(articles)}\")\n\nwith open('/kaggle/input/crunch2/questions.json', 'r', encoding='utf-8') as f:\n    questions = json.load(f)\nprint(f\"Вопросов: {len(questions)}\")\n\narticle_id_to_idx = {}\narticle_titles = []\nfor idx, article in enumerate(articles):\n    article_id = article.get('id', str(idx))\n    article_id_to_idx[article_id] = idx\n    article_titles.append(article.get('title', ''))\n\ndense_file = \"/kaggle/input/crunch2/dense_embeddings_qwen.npy\"\ndense_embeddings = np.load(dense_file)\nprint(f\"Эмбеддинги: {dense_embeddings.shape}\")\n\n# Создаем эмбеддинги для названий\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = SentenceTransformer(model_name, device=device)\n\ntitle_embeddings = model.encode(\n    article_titles,\n    batch_size=32,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\nprint(f\"Эмбеддинги названий: {title_embeddings.shape}\")\n\n# Нормализуем эмбеддинги\narticle_embeddings_norm = normalize(dense_embeddings)\ntitle_embeddings_norm = normalize(title_embeddings)\n\ndef enhanced_dense_search(query: str, k: int = 10, \n                         text_weight: float = 0.7,\n                         title_weight: float = 0.3) -> List[str]:\n    \"\"\"\n    Улучшенный поиск с учетом текста и названий статей\n    \n    Args:\n        query: текст запроса\n        k: количество результатов\n        text_weight: вес текста статьи (0-1)\n        title_weight: вес названия статьи (0-1)\n    \"\"\"\n    # Получаем эмбеддинг запроса\n    query_emb = model.encode(\n        query,\n        convert_to_numpy=True,\n        normalize_embeddings=True,\n        show_progress_bar=False\n    )\n    \n    # Поиск по тексту статей\n    text_similarities = query_emb @ article_embeddings_norm.T\n    \n    # Поиск по названиям статей\n    title_similarities = query_emb @ title_embeddings_norm.T\n    \n    # Комбинируем результаты с весами\n    combined_scores = (text_weight * text_similarities + \n                      title_weight * title_similarities)\n    \n    # Топ-K индексов\n    top_indices = np.argsort(-combined_scores)[:k]\n    \n    # Преобразуем индексы в ID\n    top_ids = []\n    for idx in top_indices:\n        # Ищем ID по индексу\n        for article_id, article_idx in article_id_to_idx.items():\n            if article_idx == idx:\n                top_ids.append(article_id)\n                break\n    \n    return top_ids\n    \ndef enhanced_time_dense_search(\n    query: str, \n    k: int = 10, \n    text_weight: float = 0.6,\n    title_weight: float = 0.2,\n    recency_weight: float = 0.2,\n    time_decay_days: int = 365  # Статьи старше года получают минимальный буст\n) -> List[str]:\n    \"\"\"\n    Улучшенный поиск с учетом текста, названий и актуальности статей\n    \"\"\"\n    # Получаем эмбеддинг запроса\n    query_emb = model.encode(\n        query,\n        convert_to_numpy=True,\n        normalize_embeddings=True,\n        show_progress_bar=False\n    )\n    \n    # Поиск по тексту статей\n    text_similarities = query_emb @ article_embeddings_norm.T\n    \n    # Поиск по названиям статей\n    title_similarities = query_emb @ title_embeddings_norm.T\n    \n    # Рассчитываем временной скор\n    current_time = datetime.now()\n    time_scores = []\n    \n    for article in articles:\n        try:\n            pub_time = datetime.fromisoformat(article.get('published_time', '2020-01-01'))\n            days_diff = (current_time - pub_time).days\n            # Экспоненциальный затухающий буст (больше для свежих статей)\n            time_score = np.exp(-days_diff / time_decay_days)\n        except:\n            time_score = 0.1  # Минимальный скор для статей без даты\n        \n        time_scores.append(time_score)\n    \n    time_scores = np.array(time_scores)\n    time_scores = time_scores / time_scores.max()  # Нормализуем к [0, 1]\n    \n    # Комбинируем результаты\n    combined_scores = (\n        text_weight * text_similarities + \n        title_weight * title_similarities +\n        recency_weight * time_scores\n    )\n    \n    # Топ-K индексов\n    top_indices = np.argsort(-combined_scores)[:k]\n    \n    # Преобразуем индексы в ID\n    top_ids = []\n    for idx in top_indices:\n        for article_id, article_idx in article_id_to_idx.items():\n            if article_idx == idx:\n                top_ids.append(article_id)\n                break\n    \n    return top_ids\n    \ndef basic_dense_search(query: str, k: int = 10) -> List[str]:\n    \"\"\"Только по тексту статей\"\"\"\n    query_emb = model.encode(\n        query,\n        convert_to_numpy=True,\n        normalize_embeddings=True,\n        show_progress_bar=False\n    )\n    \n    similarities = query_emb @ article_embeddings_norm.T\n    top_indices = np.argsort(-similarities)[:k]\n    \n    top_ids = []\n    for idx in top_indices:\n        for article_id, article_idx in article_id_to_idx.items():\n            if article_idx == idx:\n                top_ids.append(article_id)\n                break\n    \n    return top_ids\n\n# 4. Функция оценки\ndef evaluate_search(search_func, k_values=[1, 3, 5, 10]):\n    \"\"\"Оценка поиска с выводом метрик и деталей\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(\"ОЦЕНКА ПОИСКА ПО DENSE ЭМБЕДДИНГАМ\")\n    print(f\"{'='*60}\")\n    \n    results = []\n    \n    # Для каждого K считаем метрики\n    for k in k_values:\n        print(f\"\\nТОП-{k} РЕЗУЛЬТАТЫ:\")\n        print(\"-\" * 80)\n        \n        total_precision = 0\n        total_recall = 0\n        total_hit = 0\n        total_mrr = 0\n        valid_queries = 0\n        \n        # Обрабатываем каждый вопрос\n        for i, question_data in enumerate(questions):\n            query = question_data.get(\"question\", \"\")\n            correct_ids = set(question_data.get(\"id\", []))\n            \n            if not correct_ids:\n                continue\n            \n            # Поиск\n            found_ids = search_func(query, k=k)\n            \n            # Считаем метрики\n            correct_found = [id for id in found_ids if id in correct_ids]\n            \n            # Precision@K\n            precision = len(correct_found) / k if k > 0 else 0\n            \n            # Recall@K\n            recall = len(correct_found) / len(correct_ids) if correct_ids else 0\n            \n            # Hit Rate@K\n            hit = 1 if len(correct_found) > 0 else 0\n            \n            # MRR@K\n            mrr = 0\n            for rank, found_id in enumerate(found_ids, 1):\n                if found_id in correct_ids:\n                    mrr = 1.0 / rank\n                    break\n            \n            # Добавляем к итогам\n            total_precision += precision\n            total_recall += recall\n            total_hit += hit\n            total_mrr += mrr\n            valid_queries += 1\n            \n            # Выводим детали для первых 3 вопросов\n            if i < 3:\n                print(f\"\\nВопрос {i+1}: '{query[:50]}...'\")\n                print(f\"Правильные ID: {list(correct_ids)}\")\n                print(f\"Найденные ID: {found_ids}\")\n                print(f\"Совпадения: {correct_found}\")\n                print(f\"Несовпадения: {[id for id in found_ids if id not in correct_ids]}\")\n                print(f\"Precision@{k}: {precision:.3f}, Recall@{k}: {recall:.3f}\")\n        \n        # Средние метрики\n        if valid_queries > 0:\n            avg_precision = total_precision / valid_queries\n            avg_recall = total_recall / valid_queries\n            avg_hit = total_hit / valid_queries\n            avg_mrr = total_mrr / valid_queries\n            \n            # F1-score\n            f1 = 2 * avg_precision * avg_recall / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n            \n            print(f\"\\n{'='*80}\")\n            print(f\"ИТОГО ДЛЯ TOP-{k} (на {valid_queries} вопросах):\")\n            print(f\"  Precision@{k}: {avg_precision:.3f}\")\n            print(f\"  Recall@{k}:    {avg_recall:.3f}\")\n            print(f\"  F1@{k}:        {f1:.3f}\")\n            print(f\"  Hit Rate@{k}:  {avg_hit:.3f}\")\n            print(f\"  MRR@{k}:       {avg_mrr:.3f}\")\n            print(f\"{'='*80}\")\n            \n            results.append({\n                'k': k,\n                'precision': avg_precision,\n                'recall': avg_recall,\n                'f1': f1,\n                'hit_rate': avg_hit,\n                'mrr': avg_mrr\n            })\n    \n    return results\n\n\nevaluation_results = evaluate_search(enhanced_time_dense_search, k_values=[1, 3, 5, 10])\n\nprint(f\"\\n{'='*80}\")\nprint(\"СВОДНАЯ ТАБЛИЦА МЕТРИК\")\nprint(\"=\"*80)\nprint(f\"{'K':>4} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Hit Rate':>10} {'MRR':>10}\")\nprint(\"-\" * 80)\n\nfor res in evaluation_results:\n    print(f\"{res['k']:>4} \"\n          f\"{res['precision']:>10.3f} \"\n          f\"{res['recall']:>10.3f} \"\n          f\"{res['f1']:>10.3f} \"\n          f\"{res['hit_rate']:>10.3f} \"\n          f\"{res['mrr']:>10.3f}\")\n\nprint(\"=\"*80)\nsafe_model_name = model_name.replace('/', '_') \ntable_file = f\"/kaggle/working/metrics_{safe_model_name}.txt\"\nwith open(table_file, 'w', encoding='utf-8') as f:\n    # Простая таблица\n    f.write(\"Метрики поиска по dense эмбеддингам\\n\")\n    f.write(\"=\"*60 + \"\\n\")\n    f.write(\"K  Precision  Recall     F1        HitRate   MRR\\n\")\n    f.write(\"-\" * 60 + \"\\n\")\n    \n    for res in evaluation_results:\n        f.write(f\"{res['k']:2}  {res['precision']:8.3f}  {res['recall']:8.3f}  \"\n                f\"{res['f1']:8.3f}  {res['hit_rate']:8.3f}  {res['mrr']:8.3f}\\n\")\n    \n    f.write(\"=\"*60 + \"\\n\")\n\nprint(f\"Таблица сохранена в {table_file}\")\n\n# 7. Детальный анализ для всех вопросов (сохранение в файл)\nprint(\"\\nСОХРАНЕНИЕ ДЕТАЛЬНЫХ РЕЗУЛЬТАТОВ...\")\n\ndetailed_results = []\n\nfor i, question_data in enumerate(questions):\n    query = question_data.get(\"question\", \"\")\n    correct_ids = set(question_data.get(\"id\", []))\n    \n    if not correct_ids:\n        continue\n    \n    # Ищем для Top-5\n    found_ids = enhanced_time_dense_search(query, k=5)\n    \n    # Определяем совпадения\n    matches = [id for id in found_ids if id in correct_ids]\n    non_matches = [id for id in found_ids if id not in correct_ids]\n    \n    # Precision для этого запроса\n    precision_5 = len(matches) / 5 if found_ids else 0\n    \n    detailed_results.append({\n        'query_id': i + 1,\n        'query': query,\n        'correct_ids': list(correct_ids),\n        'found_ids': found_ids,\n        'matches': matches,\n        'non_matches': non_matches,\n        'precision_5': precision_5,\n        'num_matches': len(matches)\n    })\n    \n    # Выводим детали для первых 5 вопросов\n    if i < 5:\n        print(f\"\\nВопрос {i+1}:\")\n        print(f\"  Запрос: '{query[:60]}...'\")\n        print(f\"  Правильные ID: {list(correct_ids)}\")\n        print(f\"  Найденные ID: {found_ids}\")\n        print(f\"  ✓ Совпали: {matches}\")\n        print(f\"  ✗ Не совпали: {non_matches}\")\n        print(f\"  Precision@5: {precision_5:.3f}\")\n\nsafe_model_name = model_name.replace('/', '_') \noutput_file = f\"/kaggle/working/search_evaluation_details_{safe_model_name}.json\"\nwith open(output_file, 'w', encoding='utf-8') as f:\n    json.dump(detailed_results, f, indent=2, ensure_ascii=False)\n\nprint(f\"\\n✓ Детальные результаты сохранены в {output_file}\")\n\n# 8. Статистика совпадений\nprint(f\"\\n{'='*80}\")\nprint(\"СТАТИСТИКА СОВПАДЕНИЙ (Top-5)\")\nprint(\"=\"*80)\n\ntotal_questions = len([q for q in questions if q.get('id')])\ntotal_positions = total_questions * 5\ntotal_matches = sum(res['num_matches'] for res in detailed_results)\ntotal_non_matches = total_positions - total_matches\n\nprint(f\"Всего вопросов с ответами: {total_questions}\")\nprint(f\"Всего проверок (вопросов × Top-5): {total_positions}\")\nprint(f\"Всего совпадений: {total_matches}\")\nprint(f\"Всего несовпадений: {total_non_matches}\")\nprint(f\"Процент совпадений: {total_matches/total_positions*100:.1f}%\")\n\n# Распределение по количеству совпадений\nmatches_dist = {}\nfor res in detailed_results:\n    num_matches = res['num_matches']\n    matches_dist[num_matches] = matches_dist.get(num_matches, 0) + 1\n\nprint(f\"\\nРаспределение совпадений на вопрос:\")\nfor num in sorted(matches_dist.keys()):\n    count = matches_dist[num]\n    percentage = count / total_questions * 100\n    print(f\"  {num} совпадений: {count} вопросов ({percentage:.1f}%)\")\n\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T17:44:30.328481Z","iopub.execute_input":"2026-01-22T17:44:30.328876Z","iopub.status.idle":"2026-01-22T17:45:24.374576Z","shell.execute_reply.started":"2026-01-22T17:44:30.328847Z","shell.execute_reply":"2026-01-22T17:45:24.373882Z"}},"outputs":[{"name":"stdout","text":"Статей: 5488\nВопросов: 60\nЭмбеддинги: (5488, 1024)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59445d52a19b4bc49f31635935599410"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/215 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df70bb9af49a4236b1f6fa39a658db82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e150d0cbccd4078b642faa98c57e310"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc14000150248629dba8c04117cf182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c11f19ea8ed4b838244f238b7f20126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a6d67f579e3450abf08e609212e3994"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7a083945e764649840ba1cc29a89524"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"175f08c1b6a540a78c98a483751a2e63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c0f067bb4c4645a524c957916a278b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee7c0a8da4e149fdbd2d07e332f05d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/172 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccdda053549c4b078769cd52e0267c2b"}},"metadata":{}},{"name":"stdout","text":"Эмбеддинги названий: (5488, 1024)\n\n============================================================\nОЦЕНКА ПОИСКА ПО DENSE ЭМБЕДДИНГАМ\n============================================================\n\nТОП-1 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\nПравильные ID: ['13ed2979-8642-5bcd-809d-8897177f0c3d', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '69e1be8c-f789-5de3-8c1a-c89f92639178', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНайденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c']\nСовпадения: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c']\nНесовпадения: []\nPrecision@1: 1.000, Recall@1: 0.200\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\nПравильные ID: ['8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\nНайденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\nСовпадения: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\nНесовпадения: []\nPrecision@1: 1.000, Recall@1: 0.200\n\nВопрос 3: 'What's new in the Microsoft and Open AI race?...'\nПравильные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nНайденные ID: ['cae59663-09df-5005-a909-63a05a853e7f']\nСовпадения: ['cae59663-09df-5005-a909-63a05a853e7f']\nНесовпадения: []\nPrecision@1: 1.000, Recall@1: 0.333\n\n================================================================================\nИТОГО ДЛЯ TOP-1 (на 60 вопросах):\n  Precision@1: 0.800\n  Recall@1:    0.159\n  F1@1:        0.265\n  Hit Rate@1:  0.800\n  MRR@1:       0.800\n================================================================================\n\nТОП-3 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\nПравильные ID: ['13ed2979-8642-5bcd-809d-8897177f0c3d', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '69e1be8c-f789-5de3-8c1a-c89f92639178', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНайденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nСовпадения: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНесовпадения: []\nPrecision@3: 1.000, Recall@3: 0.600\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\nПравильные ID: ['8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\nНайденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\nСовпадения: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\nНесовпадения: []\nPrecision@3: 1.000, Recall@3: 0.600\n\nВопрос 3: 'What's new in the Microsoft and Open AI race?...'\nПравильные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nНайденные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '3c7862bd-11ed-5227-8b33-2ea927f24bd0']\nСовпадения: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0']\nНесовпадения: ['26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nPrecision@3: 0.667, Recall@3: 0.667\n\n================================================================================\nИТОГО ДЛЯ TOP-3 (на 60 вопросах):\n  Precision@3: 0.700\n  Recall@3:    0.417\n  F1@3:        0.523\n  Hit Rate@3:  0.867\n  MRR@3:       0.831\n================================================================================\n\nТОП-5 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\nПравильные ID: ['13ed2979-8642-5bcd-809d-8897177f0c3d', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '69e1be8c-f789-5de3-8c1a-c89f92639178', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНайденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\nСовпадения: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\nНесовпадения: []\nPrecision@5: 1.000, Recall@5: 1.000\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\nПравильные ID: ['8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\nНайденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\nСовпадения: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\nНесовпадения: []\nPrecision@5: 1.000, Recall@5: 1.000\n\nВопрос 3: 'What's new in the Microsoft and Open AI race?...'\nПравильные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nНайденные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'b94e436d-670f-567d-8fbd-c83fe965ce0f', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nСовпадения: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nНесовпадения: ['26a13d66-152b-5969-93e9-41e0b7b5c9aa', 'b94e436d-670f-567d-8fbd-c83fe965ce0f']\nPrecision@5: 0.600, Recall@5: 1.000\n\n================================================================================\nИТОГО ДЛЯ TOP-5 (на 60 вопросах):\n  Precision@5: 0.533\n  Recall@5:    0.511\n  F1@5:        0.522\n  Hit Rate@5:  0.933\n  MRR@5:       0.846\n================================================================================\n\nТОП-10 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\nПравильные ID: ['13ed2979-8642-5bcd-809d-8897177f0c3d', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '69e1be8c-f789-5de3-8c1a-c89f92639178', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНайденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178', 'f7a16c3a-fe5c-56f9-86f3-cdc674dda9f6', 'c6cc8e9d-c7d4-5409-82ac-1a157ebca402', '0ea38ba7-739e-5bff-b4be-0f6c82b3146d', '99d641d9-f659-596e-a333-9fa306675c85', 'bdfb4d03-5752-57f5-beb5-c59a2c955fb8']\nСовпадения: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\nНесовпадения: ['f7a16c3a-fe5c-56f9-86f3-cdc674dda9f6', 'c6cc8e9d-c7d4-5409-82ac-1a157ebca402', '0ea38ba7-739e-5bff-b4be-0f6c82b3146d', '99d641d9-f659-596e-a333-9fa306675c85', 'bdfb4d03-5752-57f5-beb5-c59a2c955fb8']\nPrecision@10: 0.500, Recall@10: 1.000\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\nПравильные ID: ['8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\nНайденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c', '9376fa88-18e4-5ec3-8577-4886291ab8e8', 'c6cf1538-226d-59f8-8b1d-66abd5a51f69', 'd5fb6539-585c-5763-a56f-af4cb037d569', '171ffdd4-e1a9-5d3e-b7b1-2fcb6473f78e', 'ea39e122-4f2c-5410-8aaa-0b52cddbed12']\nСовпадения: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\nНесовпадения: ['9376fa88-18e4-5ec3-8577-4886291ab8e8', 'c6cf1538-226d-59f8-8b1d-66abd5a51f69', 'd5fb6539-585c-5763-a56f-af4cb037d569', '171ffdd4-e1a9-5d3e-b7b1-2fcb6473f78e', 'ea39e122-4f2c-5410-8aaa-0b52cddbed12']\nPrecision@10: 0.500, Recall@10: 1.000\n\nВопрос 3: 'What's new in the Microsoft and Open AI race?...'\nПравильные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nНайденные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'b94e436d-670f-567d-8fbd-c83fe965ce0f', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1', 'b8f70442-b2cf-5a86-9579-cb286d041c4d', 'af2ed871-dcb1-536c-94a5-600fb6b95df1', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '625a48b4-c174-51c9-8f43-3741db1fab01']\nСовпадения: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nНесовпадения: ['26a13d66-152b-5969-93e9-41e0b7b5c9aa', 'b94e436d-670f-567d-8fbd-c83fe965ce0f', 'b8f70442-b2cf-5a86-9579-cb286d041c4d', 'af2ed871-dcb1-536c-94a5-600fb6b95df1', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '625a48b4-c174-51c9-8f43-3741db1fab01']\nPrecision@10: 0.300, Recall@10: 1.000\n\n================================================================================\nИТОГО ДЛЯ TOP-10 (на 60 вопросах):\n  Precision@10: 0.313\n  Recall@10:    0.578\n  F1@10:        0.406\n  Hit Rate@10:  0.933\n  MRR@10:       0.846\n================================================================================\n\n================================================================================\nСВОДНАЯ ТАБЛИЦА МЕТРИК\n================================================================================\n   K  Precision     Recall         F1   Hit Rate        MRR\n--------------------------------------------------------------------------------\n   1      0.800      0.159      0.265      0.800      0.800\n   3      0.700      0.417      0.523      0.867      0.831\n   5      0.533      0.511      0.522      0.933      0.846\n  10      0.313      0.578      0.406      0.933      0.846\n================================================================================\nТаблица сохранена в /kaggle/working/metrics_Qwen_Qwen3-Embedding-0.6B.txt\n\nСОХРАНЕНИЕ ДЕТАЛЬНЫХ РЕЗУЛЬТАТОВ...\n\nВопрос 1:\n  Запрос: 'What are the features that GPT-5 can provide compared to GPT...'\n  Правильные ID: ['13ed2979-8642-5bcd-809d-8897177f0c3d', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '69e1be8c-f789-5de3-8c1a-c89f92639178', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\n  Найденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\n  ✓ Совпали: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\n  ✗ Не совпали: []\n  Precision@5: 1.000\n\nВопрос 2:\n  Запрос: 'What new technologies in processor manufacturing will domina...'\n  Правильные ID: ['8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\n  Найденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\n  ✓ Совпали: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\n  ✗ Не совпали: []\n  Precision@5: 1.000\n\nВопрос 3:\n  Запрос: 'What's new in the Microsoft and Open AI race?...'\n  Правильные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\n  Найденные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'b94e436d-670f-567d-8fbd-c83fe965ce0f', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\n  ✓ Совпали: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\n  ✗ Не совпали: ['26a13d66-152b-5969-93e9-41e0b7b5c9aa', 'b94e436d-670f-567d-8fbd-c83fe965ce0f']\n  Precision@5: 0.600\n\nВопрос 4:\n  Запрос: 'How are multimodal models (text, image, video, and audio) ev...'\n  Правильные ID: ['99a179ed-b2d9-5604-a458-5c19ee8839a0', '33ca7341-8844-536a-bf4f-ff3cdfed03c5', '55421df0-b7c0-5005-a23f-22ff83a6f4b7', 'f9aa5688-9785-54a4-b377-80f0db840d10', 'd8240b33-2ec1-5da5-ad17-5cc2dfbf8b8c']\n  Найденные ID: ['d8240b33-2ec1-5da5-ad17-5cc2dfbf8b8c', 'f9aa5688-9785-54a4-b377-80f0db840d10', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '33ca7341-8844-536a-bf4f-ff3cdfed03c5', '55421df0-b7c0-5005-a23f-22ff83a6f4b7']\n  ✓ Совпали: ['d8240b33-2ec1-5da5-ad17-5cc2dfbf8b8c', 'f9aa5688-9785-54a4-b377-80f0db840d10', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '33ca7341-8844-536a-bf4f-ff3cdfed03c5', '55421df0-b7c0-5005-a23f-22ff83a6f4b7']\n  ✗ Не совпали: []\n  Precision@5: 1.000\n\nВопрос 5:\n  Запрос: 'What are AI agent systems, and how do they change the way au...'\n  Правильные ID: ['0ccf9b82-2a5d-522a-9eb2-c12eb8839587', '9c0a4b8e-704f-52f2-92ed-cc0c97da2c5d', 'fc60f3bc-4d99-595a-96bb-89b1afb489de']\n  Найденные ID: ['9c0a4b8e-704f-52f2-92ed-cc0c97da2c5d', '0ccf9b82-2a5d-522a-9eb2-c12eb8839587', 'fc60f3bc-4d99-595a-96bb-89b1afb489de', 'f837a58a-1a05-5673-885d-8eb9255426e4', 'df809136-d2b5-56a1-8300-0796991cc6e3']\n  ✓ Совпали: ['9c0a4b8e-704f-52f2-92ed-cc0c97da2c5d', '0ccf9b82-2a5d-522a-9eb2-c12eb8839587', 'fc60f3bc-4d99-595a-96bb-89b1afb489de']\n  ✗ Не совпали: ['f837a58a-1a05-5673-885d-8eb9255426e4', 'df809136-d2b5-56a1-8300-0796991cc6e3']\n  Precision@5: 0.600\n\n✓ Детальные результаты сохранены в /kaggle/working/search_evaluation_details_Qwen_Qwen3-Embedding-0.6B.json\n\n================================================================================\nСТАТИСТИКА СОВПАДЕНИЙ (Top-5)\n================================================================================\nВсего вопросов с ответами: 60\nВсего проверок (вопросов × Top-5): 300\nВсего совпадений: 160\nВсего несовпадений: 140\nПроцент совпадений: 53.3%\n\nРаспределение совпадений на вопрос:\n  0 совпадений: 4 вопросов (6.7%)\n  1 совпадений: 6 вопросов (10.0%)\n  2 совпадений: 14 вопросов (23.3%)\n  3 совпадений: 25 вопросов (41.7%)\n  4 совпадений: 4 вопросов (6.7%)\n  5 совпадений: 7 вопросов (11.7%)\n================================================================================\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"found_ids = enhanced_time_dense_search(\"What are AI agent systems, and how do they change the way automation is approached?\", k=5)\nprint(found_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T18:41:04.456096Z","iopub.execute_input":"2026-01-22T18:41:04.457060Z","iopub.status.idle":"2026-01-22T18:41:04.515410Z","shell.execute_reply.started":"2026-01-22T18:41:04.457029Z","shell.execute_reply":"2026-01-22T18:41:04.514407Z"}},"outputs":[{"name":"stdout","text":"Преобразование 83 текстов в sparse эмбеддинги...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_240/492012215.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfound_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menhanced_time_dense_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What are AI agent systems, and how do they change the way automation is approached?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_240/410859812.py\u001b[0m in \u001b[0;36menhanced_time_dense_search\u001b[0;34m(query, k, text_weight, title_weight, recency_weight, time_decay_days)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marticle_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle_id_to_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0marticle_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mtop_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"],"ename":"ValueError","evalue":"The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()","output_type":"error"}],"execution_count":13},{"cell_type":"markdown","source":"## BM25","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport re\nfrom typing import List, Dict\nimport numpy as np\n\n# Скачиваем необходимые ресурсы NLTK\ntry:\n    nltk.data.find('tokenizers/punkt')\n    nltk.data.find('corpora/stopwords')\n    nltk.data.find('corpora/wordnet')\nexcept:\n    nltk.download('punkt')\n    nltk.download('stopwords')\n    nltk.download('wordnet')\n    nltk.download('omw-eng')  # Open Multilingual WordNet\n\nclass TextPreprocessor:\n    def __init__(self, language='english'):\n        \"\"\"\n        Инициализация препроцессора текста\n        \n        Args:\n            language: язык текста ('english', 'russian')\n        \"\"\"\n        self.language = language\n        \n        # Инициализируем стеммер и лемматизатор\n        if language == 'english':\n            self.stemmer = SnowballStemmer('english')\n            self.lemmatizer = WordNetLemmatizer()\n            self.stop_words = set(stopwords.words('english'))\n    \n    def preprocess(self, text: str, use_stemming: bool = True, \n                   use_lemmatization: bool = True, remove_stopwords: bool = True) -> List[str]:\n        \"\"\"\n        Препроцессинг текста\n        \n        Args:\n            text: исходный текст\n            use_stemming: применять стемминг\n            use_lemmatization: применять лемматизацию\n            remove_stopwords: удалять стоп-слова\n            \n        Returns:\n            Список обработанных токенов\n        \"\"\"\n        if not text:\n            return []\n        \n        # 1. Приведение к нижнему регистру\n        text = text.lower()\n        \n        # 2. Удаление HTML-тегов и специальных символов\n        text = re.sub(r'<[^>]+>', ' ', text)\n        text = re.sub(r'[^\\w\\s]', ' ', text)\n        \n        # 3. Токенизация\n        tokens = nltk.word_tokenize(text)\n        \n        # 4. Фильтрация токенов\n        processed_tokens = []\n        for token in tokens:\n            # Пропускаем числа и очень короткие токены\n            if token.isdigit() or len(token) < 2:\n                continue\n                \n            # Удаление стоп-слов\n            if remove_stopwords and token in self.stop_words:\n                continue\n            \n            # Лемматизация (если доступна и включена)\n            if use_lemmatization and self.lemmatizer:\n                if self.language == 'english':\n                    # Для английского определяем часть речи\n                    token = self.lemmatizer.lemmatize(token, pos='v')  # глагол\n                    token = self.lemmatizer.lemmatize(token, pos='n')  # существительное\n                    token = self.lemmatizer.lemmatize(token, pos='a')  # прилагательное\n                    token = self.lemmatizer.lemmatize(token, pos='r')  # наречие\n            \n            # Стемминг\n            if use_stemming:\n                token = self.stemmer.stem(token)\n            \n            processed_tokens.append(token)\n        \n        return processed_tokens\n    \n    def preprocess_batch(self, texts: List[str], **kwargs) -> List[List[str]]:\n        \"\"\"Препроцессинг батча текстов\"\"\"\n        return [self.preprocess(text, **kwargs) for text in texts]\n\n\nclass BM25WithPreprocessing:\n    def __init__(self, k1: float = 1.5, b: float = 0.75, language: str = 'english'):\n        \"\"\"\n        BM25 с препроцессингом текста\n        \n        Args:\n            k1: параметр регулирования частоты термина\n            b: параметр регулирования длины документа\n            language: язык текста\n        \"\"\"\n        self.k1 = k1\n        self.b = b\n        self.preprocessor = TextPreprocessor(language)\n        \n        # Статистики корпуса\n        self.doc_freq = {}  # DF(t)\n        self.term_freq = []  # TF(t, d)\n        self.doc_lengths = []  # |d|\n        self.avg_doc_length = 0.0\n        self.num_docs = 0\n        self.vocab = set()\n        \n        # Настройки препроцессинга\n        self.use_stemming = True\n        self.use_lemmatization = True\n        self.remove_stopwords = True\n        \n    def set_preprocessing_options(self, use_stemming: bool = True, \n                                  use_lemmatization: bool = True, \n                                  remove_stopwords: bool = True):\n        \"\"\"Настройка опций препроцессинга\"\"\"\n        self.use_stemming = use_stemming\n        self.use_lemmatization = use_lemmatization\n        self.remove_stopwords = remove_stopwords\n    \n    def fit(self, documents: List[str]) -> 'BM25WithPreprocessing':\n        \"\"\"\n        Обучение BM25 на корпусе документов с препроцессингом\n        \"\"\"\n        print(f\"Обучение BM25 с препроцессингом на {len(documents)} документах...\")\n        \n        # Препроцессинг всех документов\n        print(\"Препроцессинг документов...\")\n        processed_docs = self.preprocessor.preprocess_batch(\n            documents,\n            use_stemming=self.use_stemming,\n            use_lemmatization=self.use_lemmatization,\n            remove_stopwords=self.remove_stopwords\n        )\n        \n        self.num_docs = len(processed_docs)\n        self.doc_freq = {}\n        self.term_freq = []\n        self.doc_lengths = []\n        \n        total_length = 0\n        \n        for doc_tokens in processed_docs:\n            # Длина документа\n            doc_len = len(doc_tokens)\n            self.doc_lengths.append(doc_len)\n            total_length += doc_len\n            \n            # Частоты терминов в документе\n            term_counts = {}\n            for token in doc_tokens:\n                term_counts[token] = term_counts.get(token, 0) + 1\n            self.term_freq.append(term_counts)\n            \n            # Обновляем document frequency\n            for term in term_counts.keys():\n                self.doc_freq[term] = self.doc_freq.get(term, 0) + 1\n                self.vocab.add(term)\n        \n        # Средняя длина документа\n        self.avg_doc_length = total_length / self.num_docs if self.num_docs > 0 else 0\n        \n        print(f\"Обучение завершено:\")\n        print(f\"  - Документов: {self.num_docs}\")\n        print(f\"  - Уникальных терминов (после препроцессинга): {len(self.vocab)}\")\n        print(f\"  - Средняя длина документа: {self.avg_doc_length:.1f} токенов\")\n        \n        return self\n    \n    def tokenize_query(self, query: str) -> List[str]:\n        \"\"\"Токенизация запроса с тем же препроцессингом\"\"\"\n        return self.preprocessor.preprocess(\n            query,\n            use_stemming=self.use_stemming,\n            use_lemmatization=self.use_lemmatization,\n            remove_stopwords=self.remove_stopwords\n        )\n    \n    def idf(self, term: str) -> float:\n        \"\"\"Inverse Document Frequency\"\"\"\n        import math\n        if term not in self.doc_freq:\n            return 0.0\n        \n        df_t = self.doc_freq[term]\n        numerator = self.num_docs - df_t + 0.5\n        denominator = df_t + 0.5\n        \n        if denominator <= 0 or numerator <= 0:\n            return 0.0\n        \n        return math.log(numerator / denominator + 1)\n    \n    def tf_component(self, tf: int, doc_len: int) -> float:\n        \"\"\"Term Frequency компонент\"\"\"\n        length_norm = 1 - self.b + self.b * (doc_len / self.avg_doc_length)\n        numerator = tf * (self.k1 + 1)\n        denominator = tf + self.k1 * length_norm\n        return numerator / denominator if denominator > 0 else 0.0\n    \n    def search(self, query: str, k: int = 10) -> tuple:\n        \"\"\"\n        Поиск по запросу с препроцессингом\n        \"\"\"\n        # Токенизация запроса\n        query_tokens = self.tokenize_query(query)\n        \n        if not query_tokens:\n            return [], []\n        \n        # Подсчет частот терминов в запросе\n        query_term_counts = {}\n        for token in query_tokens:\n            query_term_counts[token] = query_term_counts.get(token, 0) + 1\n        \n        # Вычисление скоров\n        scores = np.zeros(self.num_docs)\n        \n        for doc_idx in range(self.num_docs):\n            doc_score = 0.0\n            doc_len = self.doc_lengths[doc_idx]\n            \n            for term, query_tf in query_term_counts.items():\n                idf_score = self.idf(term)\n                \n                if idf_score > 0:\n                    doc_tf = self.term_freq[doc_idx].get(term, 0)\n                    \n                    if doc_tf > 0:\n                        tf_component = self.tf_component(doc_tf, doc_len)\n                        doc_score += idf_score * tf_component\n            \n            scores[doc_idx] = doc_score\n        \n        # Получаем топ-K\n        if k > len(scores):\n            k = len(scores)\n        \n        top_indices = np.argpartition(-scores, k)[:k]\n        sorted_indices = top_indices[np.argsort(-scores[top_indices])]\n        sorted_scores = scores[sorted_indices]\n        \n        return sorted_indices.tolist(), sorted_scores.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T17:43:23.023329Z","iopub.execute_input":"2026-01-25T17:43:23.023680Z","iopub.status.idle":"2026-01-25T17:43:23.047120Z","shell.execute_reply.started":"2026-01-25T17:43:23.023655Z","shell.execute_reply":"2026-01-25T17:43:23.046382Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Error loading omw-eng: Package 'omw-eng' not found in\n[nltk_data]     index\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def train_bm25_with_preprocessing(articles: List[Dict], \n                                 use_stemming: bool = True,\n                                 use_lemmatization: bool = True,\n                                 remove_stopwords: bool = True,\n                                 language: str = 'english') -> tuple:\n    \"\"\"\n    Обучение BM25 на статьях с препроцессингом\n    \n    Args:\n        articles: список статей\n        use_stemming: применять стемминг\n        use_lemmatization: применять лемматизацию\n        remove_stopwords: удалять стоп-слова\n        language: язык текста\n        \n    Returns:\n        Обученная модель BM25 и метаданные\n    \"\"\"\n    print(\"=\"*80)\n    print(\"ОБУЧЕНИЕ BM25 С ПРЕПРОЦЕССИНГОМ\")\n    print(\"=\"*80)\n    \n    article_texts = []\n    article_metadata = []\n    \n    for article in articles:\n        title = article.get('title', '')\n        text = article.get('text', '')\n        combined = f\"{title}. {text}\"\n        article_texts.append(combined)\n\n        article_metadata.append({\n            'id': article.get('id', ''),\n            'title': title,\n            'published_time': article.get('published_time', ''),\n            'original_text_preview': text[:200] if text else ''\n        })\n    \n    print(f\"Подготовлено {len(article_texts)} статей для обучения\")\n    print(f\"Настройки препроцессинга:\")\n    print(f\"  - Стемминг: {'ВКЛ' if use_stemming else 'ВЫКЛ'}\")\n    print(f\"  - Лемматизация: {'ВКЛ' if use_lemmatization else 'ВЫКЛ'}\")\n    print(f\"  - Удаление стоп-слов: {'ВКЛ' if remove_stopwords else 'ВЫКЛ'}\")\n    print(f\"  - Язык: {language}\")\n    \n    # Создаем и обучаем модель\n    bm25_model = BM25WithPreprocessing(k1=1.5, b=0.75, language=language)\n    bm25_model.set_preprocessing_options(\n        use_stemming=use_stemming,\n        use_lemmatization=use_lemmatization,\n        remove_stopwords=remove_stopwords\n    )\n    \n    bm25_model.fit(article_texts)\n    \n    return bm25_model, article_metadata\n\n\nclass BM25SearchSystem:\n    def __init__(self, bm25_model, article_metadata, article_id_to_idx):\n        \"\"\"\n        Система поиска на основе BM25\n        \n        Args:\n            bm25_model: обученная модель BM25\n            article_metadata: метаданные статей\n            article_id_to_idx: маппинг ID -> индекс\n        \"\"\"\n        self.bm25 = bm25_model\n        self.article_metadata = article_metadata\n        self.id_to_idx = article_id_to_idx\n        self.idx_to_id = {idx: aid for aid, idx in article_id_to_idx.items()}\n        \n    def search(self, query: str, k: int = 10) -> List[Dict]:\n        \"\"\"\n        Поиск статей по запросу\n        \n        Args:\n            query: поисковый запрос\n            k: количество результатов\n            \n        Returns:\n            Список найденных статей с метаданными\n        \"\"\"\n        indices, scores = self.bm25.search(query, k)\n\n        results = []\n        for idx, score in zip(indices, scores):\n            if idx < len(self.article_metadata):\n                metadata = self.article_metadata[idx]\n                result = {\n                    'id': metadata['id'],\n                    'title': metadata['title'],\n                    'score': float(score),\n                    'published_time': metadata.get('published_time', ''),\n                    'rank': len(results) + 1\n                }\n                results.append(result)\n        \n        return results\n    \n    def search_ids(self, query: str, k: int = 10) -> List[str]:\n        \"\"\"\n        Поиск только ID статей\n        \n        Args:\n            query: поисковый запрос\n            k: количество результатов\n            \n        Returns:\n            Список ID статей\n        \"\"\"\n        indices, _ = self.bm25.search(query, k)\n        article_ids = []\n        \n        for idx in indices:\n            if idx in self.idx_to_id:\n                article_ids.append(self.idx_to_id[idx])\n            elif 0 <= idx < len(self.article_metadata):\n                article_ids.append(self.article_metadata[idx]['id'])\n        \n        return article_ids","metadata":{"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<function __main__.train_bm25_with_preprocessing(articles: List[Dict], use_stemming: bool = True, use_lemmatization: bool = True, remove_stopwords: bool = True, language: str = 'english') -> tuple>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"with open('/kaggle/input/crunch/techcrunch_ai_5488_articles_20260112_1535.json', 'r', encoding='utf-8') as f:\n    articles = json.load(f)\n\nprint(f\"Загружено {len(articles)} статей\")\n\nbm25_model, article_metadata = train_bm25_with_preprocessing(articles)\n\narticle_id_to_idx = {}\nfor idx, article in enumerate(articles):\n    article_id = article.get('id', str(idx))\n    article_id_to_idx[article_id] = idx\n\nbm25_search = BM25SearchSystem(bm25_model, article_metadata, article_id_to_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T17:43:31.906844Z","iopub.execute_input":"2026-01-25T17:43:31.907130Z","iopub.status.idle":"2026-01-25T17:44:34.314029Z","shell.execute_reply.started":"2026-01-25T17:43:31.907108Z","shell.execute_reply":"2026-01-25T17:44:34.313246Z"}},"outputs":[{"name":"stdout","text":"Загружено 5488 статей\n================================================================================\nОБУЧЕНИЕ BM25 С ПРЕПРОЦЕССИНГОМ\n================================================================================\nПодготовлено 5488 статей для обучения\nНастройки препроцессинга:\n  - Стемминг: ВКЛ\n  - Лемматизация: ВКЛ\n  - Удаление стоп-слов: ВКЛ\n  - Язык: english\nОбучение BM25 с препроцессингом на 5488 документах...\nПрепроцессинг документов...\nОбучение завершено:\n  - Документов: 5488\n  - Уникальных терминов (после препроцессинга): 60846\n  - Средняя длина документа: 429.5 токенов\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def save_embeddings_minimal(bm25_model):\n\n    from scipy import sparse\n    \n    num_docs = bm25_model.num_docs\n    vocab = list(bm25_model.doc_freq.keys())\n    term_idx = {t:i for i,t in enumerate(vocab)}\n    \n    rows, cols, data = [], [], []\n    \n    for d in range(num_docs):\n        for t, tf in bm25_model.term_freq[d].items():\n            if t in term_idx:\n                ti = term_idx[t]\n                tfidf = bm25_model.tf_component(tf, bm25_model.doc_lengths[d]) * bm25_model.idf(t)\n                rows.append(d)\n                cols.append(ti)\n                data.append(tfidf)\n    \n    matrix = sparse.csr_matrix((data, (rows, cols)), shape=(num_docs, len(vocab)))\n    print(matrix.shape[1])\n    sparse.save_npz('/kaggle/working/bm25_matrix.npz', matrix)\n    \n    return '/kaggle/working/bm25_matrix.npz'\n\nmatrix_file = save_embeddings_minimal(bm25_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T17:45:10.396968Z","iopub.execute_input":"2026-01-25T17:45:10.397535Z","iopub.status.idle":"2026-01-25T17:45:13.166931Z","shell.execute_reply.started":"2026-01-25T17:45:10.397507Z","shell.execute_reply":"2026-01-25T17:45:13.166327Z"}},"outputs":[{"name":"stdout","text":"60846\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def bm25_search_function(query: str, k: int = 10) -> List[str]:\n    \"\"\"Функция поиска BM25 для интеграции с вашей системой оценки\"\"\"\n    return bm25_search.search_ids(query, k=k)\n\n\ndef evaluate_bm25_search(search_func, k_values=[1, 3, 5, 10]):\n    \"\"\"Оценка BM25 поиска\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(\"ОЦЕНКА BM25 ПОИСКА\")\n    print(f\"{'='*60}\")\n    \n    with open('/kaggle/input/crunch2/questions.json', 'r', encoding='utf-8') as f:\n        questions = json.load(f)\n    \n    results = []\n    \n    for k in k_values:\n        print(f\"\\nТОП-{k} РЕЗУЛЬТАТЫ:\")\n        print(\"-\" * 80)\n        \n        total_precision = 0\n        total_recall = 0\n        total_hit = 0\n        total_mrr = 0\n        valid_queries = 0\n        \n        for i, question_data in enumerate(questions):\n            query = question_data.get(\"question\", \"\")\n            correct_ids = set(question_data.get(\"id\", []))\n            \n            if not correct_ids:\n                continue\n\n            found_ids = search_func(query, k=k)\n\n            correct_found = [id for id in found_ids if id in correct_ids]\n            \n            precision = len(correct_found) / k if k > 0 else 0\n            recall = len(correct_found) / len(correct_ids) if correct_ids else 0\n            hit = 1 if len(correct_found) > 0 else 0\n            \n            mrr = 0\n            for rank, found_id in enumerate(found_ids, 1):\n                if found_id in correct_ids:\n                    mrr = 1.0 / rank\n                    break\n            \n            total_precision += precision\n            total_recall += recall\n            total_hit += hit\n            total_mrr += mrr\n            valid_queries += 1\n            \n            if i < 2:\n                print(f\"\\nВопрос {i+1}: '{query[:50]}...'\")\n                print(f\"  Правильные: {list(correct_ids)}\")\n                print(f\"  Найденные: {found_ids}\")\n                print(f\"  Precision@{k}: {precision:.3f}, Recall@{k}: {recall:.3f}\")\n        \n        if valid_queries > 0:\n            avg_precision = total_precision / valid_queries\n            avg_recall = total_recall / valid_queries\n            avg_hit = total_hit / valid_queries\n            avg_mrr = total_mrr / valid_queries\n            \n            f1 = 2 * avg_precision * avg_recall / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n            \n            print(f\"\\n{'='*80}\")\n            print(f\"ИТОГО ДЛЯ TOP-{k} (на {valid_queries} вопросах):\")\n            print(f\"  Precision@{k}: {avg_precision:.3f}\")\n            print(f\"  Recall@{k}:    {avg_recall:.3f}\")\n            print(f\"  F1@{k}:        {f1:.3f}\")\n            print(f\"  Hit Rate@{k}:  {avg_hit:.3f}\")\n            print(f\"  MRR@{k}:       {avg_mrr:.3f}\")\n            print(f\"{'='*80}\")\n            \n            results.append({\n                'k': k,\n                'precision': avg_precision,\n                'recall': avg_recall,\n                'f1': f1,\n                'hit_rate': avg_hit,\n                'mrr': avg_mrr\n            })\n    \n    return results\n\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"НАЧАЛО ОЦЕНКИ BM25\")\nprint(\"=\"*80)\n\nevaluation_results = evaluate_bm25_search(bm25_search_function, k_values=[1, 3, 5, 10])\n\nprint(f\"\\n{'='*80}\")\nprint(\"СВОДНАЯ ТАБЛИЦА МЕТРИК BM25\")\nprint(\"=\"*80)\nprint(f\"{'K':>4} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Hit Rate':>10} {'MRR':>10}\")\nprint(\"-\" * 80)\n\nfor res in evaluation_results:\n    print(f\"{res['k']:>4} \"\n          f\"{res['precision']:>10.3f} \"\n          f\"{res['recall']:>10.3f} \"\n          f\"{res['f1']:>10.3f} \"\n          f\"{res['hit_rate']:>10.3f} \"\n          f\"{res['mrr']:>10.3f}\")\n\nprint(\"=\"*80)\n\nwith open('/kaggle/working/bm25_metrics.txt', 'w', encoding='utf-8') as f:\n    f.write(\"Метрики BM25 поиска\\n\")\n    f.write(\"=\"*60 + \"\\n\")\n    f.write(\"K  Precision  Recall     F1        HitRate   MRR\\n\")\n    f.write(\"-\" * 60 + \"\\n\")\n    \n    for res in evaluation_results:\n        f.write(f\"{res['k']:2}  {res['precision']:8.3f}  {res['recall']:8.3f}  \"\n                f\"{res['f1']:8.3f}  {res['hit_rate']:8.3f}  {res['mrr']:8.3f}\\n\")\n    \n    f.write(\"=\"*60 + \"\\n\")\n\nprint(\"Результаты сохранены в /kaggle/working/bm25_metrics.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T17:45:26.132141Z","iopub.execute_input":"2026-01-25T17:45:26.132729Z","iopub.status.idle":"2026-01-25T17:45:33.846983Z","shell.execute_reply.started":"2026-01-25T17:45:26.132701Z","shell.execute_reply":"2026-01-25T17:45:33.846315Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nНАЧАЛО ОЦЕНКИ BM25\n================================================================================\n\n============================================================\nОЦЕНКА BM25 ПОИСКА\n============================================================\n\nТОП-1 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\n  Правильные: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '69e1be8c-f789-5de3-8c1a-c89f92639178']\n  Найденные: ['424d6560-9035-5bba-aa27-771e679fce30']\n  Precision@1: 0.000, Recall@1: 0.000\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\n  Правильные: ['821d70b8-720d-5430-8fe5-3f679ffdfdc7', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '8b678d66-56a3-55b5-9eb0-bcf11368c852']\n  Найденные: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\n  Precision@1: 1.000, Recall@1: 0.200\n\n================================================================================\nИТОГО ДЛЯ TOP-1 (на 60 вопросах):\n  Precision@1: 0.200\n  Recall@1:    0.038\n  F1@1:        0.064\n  Hit Rate@1:  0.200\n  MRR@1:       0.200\n================================================================================\n\nТОП-3 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\n  Правильные: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '69e1be8c-f789-5de3-8c1a-c89f92639178']\n  Найденные: ['424d6560-9035-5bba-aa27-771e679fce30', 'c6cc8e9d-c7d4-5409-82ac-1a157ebca402', '5a46c638-e963-5132-bb0c-c79cc600c236']\n  Precision@3: 0.000, Recall@3: 0.000\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\n  Правильные: ['821d70b8-720d-5430-8fe5-3f679ffdfdc7', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '8b678d66-56a3-55b5-9eb0-bcf11368c852']\n  Найденные: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'b53b5117-b4c2-5793-a98a-8aab78eb714f', 'bbbb5add-d6d6-5aad-8461-9ea15117ca65']\n  Precision@3: 0.333, Recall@3: 0.200\n\n================================================================================\nИТОГО ДЛЯ TOP-3 (на 60 вопросах):\n  Precision@3: 0.150\n  Recall@3:    0.082\n  F1@3:        0.106\n  Hit Rate@3:  0.350\n  MRR@3:       0.264\n================================================================================\n\nТОП-5 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\n  Правильные: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '69e1be8c-f789-5de3-8c1a-c89f92639178']\n  Найденные: ['424d6560-9035-5bba-aa27-771e679fce30', 'c6cc8e9d-c7d4-5409-82ac-1a157ebca402', '5a46c638-e963-5132-bb0c-c79cc600c236', '12aa1e39-6d66-5491-912c-f2f551b4110a', '4c4170c6-2e36-52a8-8da0-9ed306731011']\n  Precision@5: 0.000, Recall@5: 0.000\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\n  Правильные: ['821d70b8-720d-5430-8fe5-3f679ffdfdc7', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '8b678d66-56a3-55b5-9eb0-bcf11368c852']\n  Найденные: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'b53b5117-b4c2-5793-a98a-8aab78eb714f', 'bbbb5add-d6d6-5aad-8461-9ea15117ca65', '23a4b93f-5df8-5423-8c17-0653382dcef5', 'd03875f9-0608-5436-880c-26f488be1190']\n  Precision@5: 0.200, Recall@5: 0.200\n\n================================================================================\nИТОГО ДЛЯ TOP-5 (на 60 вопросах):\n  Precision@5: 0.157\n  Recall@5:    0.140\n  F1@5:        0.148\n  Hit Rate@5:  0.517\n  MRR@5:       0.301\n================================================================================\n\nТОП-10 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\n  Правильные: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '69e1be8c-f789-5de3-8c1a-c89f92639178']\n  Найденные: ['424d6560-9035-5bba-aa27-771e679fce30', 'c6cc8e9d-c7d4-5409-82ac-1a157ebca402', '5a46c638-e963-5132-bb0c-c79cc600c236', '12aa1e39-6d66-5491-912c-f2f551b4110a', '4c4170c6-2e36-52a8-8da0-9ed306731011', 'ac39a5d8-dccf-5291-9787-9fa6b6595af2', 'fadaae69-9636-5ce8-818d-78d56483e9ab', '1dcd8407-4421-5a4d-ae1f-2f62cf9fc893', '62e6bde5-3327-5991-8138-43728251a42b', '50882a61-4690-5d38-b802-aeba7f86c698']\n  Precision@10: 0.000, Recall@10: 0.000\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\n  Правильные: ['821d70b8-720d-5430-8fe5-3f679ffdfdc7', '7ab20568-f68c-5cfe-a657-14c93f76771c', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '8b678d66-56a3-55b5-9eb0-bcf11368c852']\n  Найденные: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'b53b5117-b4c2-5793-a98a-8aab78eb714f', 'bbbb5add-d6d6-5aad-8461-9ea15117ca65', '23a4b93f-5df8-5423-8c17-0653382dcef5', 'd03875f9-0608-5436-880c-26f488be1190', '85b2b47c-1ba7-59af-a84d-6d1eb5a7a7a7', '82123e5b-c42d-5a4c-b2e1-ab7aaebea431', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', 'de6fe6d8-0a15-5160-9018-a0c5e19af795', '497e4060-ed42-58e4-b4af-b9e8e7309402']\n  Precision@10: 0.200, Recall@10: 0.400\n\n================================================================================\nИТОГО ДЛЯ TOP-10 (на 60 вопросах):\n  Precision@10: 0.115\n  Recall@10:    0.195\n  F1@10:        0.145\n  Hit Rate@10:  0.567\n  MRR@10:       0.310\n================================================================================\n\n================================================================================\nСВОДНАЯ ТАБЛИЦА МЕТРИК BM25\n================================================================================\n   K  Precision     Recall         F1   Hit Rate        MRR\n--------------------------------------------------------------------------------\n   1      0.200      0.038      0.064      0.200      0.200\n   3      0.150      0.082      0.106      0.350      0.264\n   5      0.157      0.140      0.148      0.517      0.301\n  10      0.115      0.195      0.145      0.567      0.310\n================================================================================\nРезультаты сохранены в /kaggle/working/bm25_metrics.txt\n","output_type":"stream"}],"execution_count":11}]}