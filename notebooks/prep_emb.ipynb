{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14561731,"sourceType":"datasetVersion","datasetId":9301146},{"sourceId":14584026,"sourceType":"datasetVersion","datasetId":9316141}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Новый подход","metadata":{}},{"cell_type":"code","source":"from abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Optional, Union, Generator\nimport numpy as np\nfrom scipy.sparse import csr_matrix, csc_matrix, save_npz, load_npz\nimport json\nimport pickle\nfrom pathlib import Path\nimport psutil\nimport os\nimport gc\nimport time\nfrom dataclasses import dataclass\nimport warnings\nimport re\nwarnings.filterwarnings('ignore')\n\n\ndef clean_text_for_embedding(text):\n    \"\"\"\n    Быстрая чистка текста для эмбеддингов\n    \"\"\"\n    if not isinstance(text, str):\n        return \"\"\n    \n    # 1. Удаляем ссылки и email\n    text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\S+', '', text, flags=re.MULTILINE)\n    \n    # 2. Удаляем специальные символы и цифры в скобках (например, (1), (2))\n    text = re.sub(r'\\(\\d+\\)', '', text)\n    \n    # 3. Удаляем подписи подкастов и списки\n    text = re.sub(r'Subscribe to.*casts\\.', '', text, flags=re.DOTALL)\n    text = re.sub(r'Listen to.*episode.*:', '', text, flags=re.DOTALL)\n    text = re.sub(r'You also can follow.*@\\w+', '', text)\n    \n    # 4. Удаляем множественные переносы строк\n    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n    text = re.sub(r'\\n+', ' ', text)\n    \n    # 5. Удаляем лишние пробелы\n    text = ' '.join(text.split())\n    \n    return text.strip()\n\n\n@dataclass\nclass EmbeddingConfig:\n    \"\"\"Конфигурация для генерации эмбеддингов\"\"\"\n    batch_size: int = 32\n    use_mmap: bool = True  # Использовать memory-mapped файлы для больших данных\n    temp_dir: str = \"./temp_embeddings\"\n    max_memory_gb: float = 4.0  # Максимальное использование памяти в GB\n    dtype: str = \"float32\"\n\nclass BaseEmbeddingGenerator(ABC):\n    \"\"\"Базовый абстрактный класс для генераторов эмбеддингов\"\"\"\n    \n    def __init__(self, config: EmbeddingConfig = None):\n        self.config = config or EmbeddingConfig()\n        Path(self.config.temp_dir).mkdir(parents=True, exist_ok=True)\n        \n    @abstractmethod\n    def fit(self, texts: List[str]) -> 'BaseEmbeddingGenerator':\n        \"\"\"Обучение модели на текстах\"\"\"\n        pass\n    \n    @abstractmethod\n    def transform(self, texts: List[str]) -> Union[np.ndarray, csr_matrix]:\n        \"\"\"Преобразование текстов в эмбеддинги\"\"\"\n        pass\n    \n    @abstractmethod\n    def fit_transform(self, texts: List[str]) -> Union[np.ndarray, csr_matrix]:\n        \"\"\"Обучение и преобразование\"\"\"\n        pass\n    \n    def save(self, path: str) -> None:\n        \"\"\"Сохранение модели\"\"\"\n        save_path = Path(path)\n        save_path.mkdir(parents=True, exist_ok=True)\n        \n        # Сохраняем конфиг\n        config_path = save_path / \"config.json\"\n        with open(config_path, 'w') as f:\n            json.dump(self.config.__dict__, f)\n    \n    @classmethod\n    def load(cls, path: str) -> 'BaseEmbeddingGenerator':\n        \"\"\"Загрузка модели\"\"\"\n        pass\n    \n    def _check_memory_usage(self) -> bool:\n        \"\"\"Проверка использования памяти\"\"\"\n        process = psutil.Process(os.getpid())\n        memory_gb = process.memory_info().rss / 1024 / 1024 / 1024\n        \n        if memory_gb > self.config.max_memory_gb:\n            print(f\"⚠️ Предупреждение: Использовано {memory_gb:.2f} GB памяти \"\n                  f\"(лимит: {self.config.max_memory_gb} GB)\")\n            return False\n        return True\n    \n    def _batch_generator(self, data: List, batch_size: int) -> Generator:\n        \"\"\"Генератор батчей\"\"\"\n        for i in range(0, len(data), batch_size):\n            yield data[i:i + batch_size]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:58:40.235184Z","iopub.execute_input":"2026-01-22T14:58:40.235424Z","iopub.status.idle":"2026-01-22T14:58:40.824190Z","shell.execute_reply.started":"2026-01-22T14:58:40.235392Z","shell.execute_reply":"2026-01-22T14:58:40.823407Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import normalize\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\n\nclass BM25Vectorizer:\n    \"\"\"Оптимизированный BM25 векторайзер\"\"\"\n    def __init__(self, k1: float = 1.5, b: float = 0.75, \n                 max_features: int = 50000, \n                 language: str = \"russian\",\n                 use_stopwords: bool = True,\n                 use_stemming: bool = False):\n        self.k1 = k1\n        self.b = b\n        self.max_features = max_features\n        self.language = language\n        self.use_stopwords = use_stopwords\n        self.use_stemming = use_stemming\n        \n        # Инициализация компонентов\n        self.stemmer = SnowballStemmer(language) if use_stemming else None\n        self.stop_words = set(stopwords.words(language)) if use_stopwords else None\n        self.vectorizer = None\n        self.avgdl = 0.0\n        self.idf = None\n        self.vocabulary_ = None\n        \n    def _preprocess_text(self, text: str) -> str:\n        \"\"\"Предобработка текста\"\"\"\n        text = clean_text_for_embedding(text)\n        if self.use_stemming and self.stemmer:\n            tokens = word_tokenize(text.lower())\n            tokens = [self.stemmer.stem(t) for t in tokens \n                     if t.isalpha() and len(t) > 2]\n            if self.use_stopwords and self.stop_words:\n                tokens = [t for t in tokens if t not in self.stop_words]\n            return ' '.join(tokens)\n        return text.lower()\n    \n    def fit(self, texts: List[str]):\n        \"\"\"Обучение BM25\"\"\"\n        print(\"Обучение BM25 векторайзера...\")\n        \n        # Предобработка\n        processed_texts = [self._preprocess_text(t) for t in texts]\n        \n        # TF векторайзер\n        self.vectorizer = CountVectorizer(\n            max_features=self.max_features,\n            stop_words=list(self.stop_words) if self.use_stopwords else None,\n            lowercase=True\n        )\n        \n        # Вычисление TF\n        tf_matrix = self.vectorizer.fit_transform(processed_texts)\n        self.vocabulary_ = self.vectorizer.vocabulary_\n        \n        # Вычисление среднего длины документа\n        doc_lengths = tf_matrix.sum(axis=1).A1\n        self.avgdl = doc_lengths.mean()\n        \n        # Вычисление IDF\n        n_docs = tf_matrix.shape[0]\n        df = (tf_matrix > 0).sum(axis=0).A1\n        self.idf = np.log((n_docs - df + 0.5) / (df + 0.5) + 1.0)\n        \n        return self\n    \n    def transform(self, texts: List[str]) -> csr_matrix:\n        \"\"\"Преобразование текстов в BM25 векторы\"\"\"\n        if self.vectorizer is None:\n            raise ValueError(\"Сначала вызовите fit()\")\n        \n        processed_texts = [self._preprocess_text(t) for t in texts]\n        tf_matrix = self.vectorizer.transform(processed_texts)\n        \n        # Вычисление BM25\n        doc_lengths = tf_matrix.sum(axis=1).A1\n        tf = tf_matrix.tocsc()\n        \n        # Вычисление BM25 для каждого элемента\n        k1 = self.k1\n        b = self.b\n        avgdl = self.avgdl\n        \n        # Вычисление score\n        rows, cols = tf.nonzero()\n        data = tf.data\n        \n        for i in range(len(data)):\n            doc_len = doc_lengths[rows[i]]\n            tf_val = data[i]\n            idf_val = self.idf[cols[i]]\n            \n            numerator = tf_val * (k1 + 1)\n            denominator = tf_val + k1 * (1 - b + b * doc_len / avgdl)\n            \n            data[i] = idf_val * numerator / denominator\n        \n        return tf.tocsr()\n\nclass SparseEmbeddingGenerator(BaseEmbeddingGenerator):\n    \"\"\"Генератор sparse эмбеддингов (BM25)\"\"\"\n    \n    def __init__(self, \n                 language: str = \"russian\",\n                 use_stopwords: bool = True,\n                 use_stemming: bool = False,\n                 max_features: int = 50000,\n                 bm25_k1: float = 1.5,\n                 bm25_b: float = 0.75,\n                 config: EmbeddingConfig = None):\n        super().__init__(config)\n        \n        self.language = language\n        self.use_stopwords = use_stopwords\n        self.use_stemming = use_stemming\n        self.max_features = max_features\n        self.bm25_k1 = bm25_k1\n        self.bm25_b = bm25_b\n        \n        self.bm25 = None\n        self.vocabulary_size = 0\n        \n    def fit(self, texts: List[str]) -> 'SparseEmbeddingGenerator':\n        \"\"\"Обучение BM25 на текстах\"\"\"\n        print(f\"Обучение sparse модели (BM25) на {len(texts)} документах...\")\n        \n        self.bm25 = BM25Vectorizer(\n            k1=self.bm25_k1,\n            b=self.bm25_b,\n            max_features=self.max_features,\n            language=self.language,\n            use_stopwords=self.use_stopwords,\n            use_stemming=self.use_stemming\n        )\n        \n        self.bm25.fit(texts)\n        self.vocabulary_size = len(self.bm25.vocabulary_)\n        \n        print(f\"✓ Обучение завершено. Словарь: {self.vocabulary_size} токенов\")\n        return self\n    \n    def transform(self, texts: List[str], \n                  save_to_file: Optional[str] = None) -> csr_matrix:\n        \"\"\"Преобразование текстов в sparse эмбеддинги\"\"\"\n        if self.bm25 is None:\n            raise ValueError(\"Сначала вызовите fit()\")\n        \n        print(f\"Преобразование {len(texts)} текстов в sparse эмбеддинги...\")\n        \n        # Используем батчи для больших данных\n        if len(texts) > 10000 and self.config.use_mmap:\n            return self._transform_large(texts, save_to_file)\n        \n        # Для небольших данных\n        embeddings = self.bm25.transform(texts)\n        \n        if save_to_file:\n            save_npz(save_to_file, embeddings)\n            print(f\"✓ Эмбеддинги сохранены в {save_to_file}\")\n        \n        return embeddings\n    \n    def _transform_large(self, texts: List[str], \n                        save_to_file: Optional[str]) -> csr_matrix:\n        \"\"\"Преобразование больших объемов данных\"\"\"\n        print(\"Используем батчевую обработку для больших данных...\")\n        \n        batch_size = self.config.batch_size * 10  # Увеличиваем для sparse\n        temp_files = []\n        \n        for i, batch in enumerate(self._batch_generator(texts, batch_size)):\n            if i % 10 == 0:\n                print(f\"  Обработано {i * batch_size} документов\")\n                self._check_memory_usage()\n            \n            # Преобразуем батч\n            batch_emb = self.bm25.transform(batch)\n            \n            # Сохраняем на диск\n            temp_file = Path(self.config.temp_dir) / f\"sparse_batch_{i}.npz\"\n            save_npz(temp_file, batch_emb)\n            temp_files.append(temp_file)\n            \n            # Очищаем память\n            del batch_emb\n            gc.collect()\n        \n        # Объединяем результаты\n        print(\"Объединение результатов...\")\n        embeddings = self._merge_sparse_files(temp_files)\n        \n        # Сохраняем итоговый файл\n        if save_to_file:\n            save_npz(save_to_file, embeddings)\n        \n        # Удаляем временные файлы\n        for temp_file in temp_files:\n            temp_file.unlink()\n        \n        return embeddings\n    \n    def _merge_sparse_files(self, file_paths: List[Path]) -> csr_matrix:\n        \"\"\"Объединение sparse матриц с диска\"\"\"\n        from scipy.sparse import vstack\n        \n        matrices = []\n        for i, file_path in enumerate(file_paths):\n            if i % 10 == 0:\n                print(f\"  Загрузка файла {i}/{len(file_paths)}\")\n            matrices.append(load_npz(file_path))\n        \n        print(\"  Объединение матриц...\")\n        result = vstack(matrices)\n        \n        # Очищаем память\n        del matrices\n        gc.collect()\n        \n        return result\n    \n    def fit_transform(self, texts: List[str], \n                     save_to_file: Optional[str] = None) -> csr_matrix:\n        \"\"\"Обучение и преобразование\"\"\"\n        self.fit(texts)\n        return self.transform(texts, save_to_file)\n    \n    def save(self, path: str) -> None:\n        \"\"\"Сохранение модели\"\"\"\n        super().save(path)\n        save_path = Path(path)\n        \n        if self.bm25:\n            model_path = save_path / \"bm25_model.pkl\"\n            with open(model_path, 'wb') as f:\n                pickle.dump({\n                    'bm25': self.bm25,\n                    'vocabulary_size': self.vocabulary_size,\n                    'language': self.language,\n                    'max_features': self.max_features\n                }, f)\n    \n    @classmethod\n    def load(cls, path: str) -> 'SparseEmbeddingGenerator':\n        \"\"\"Загрузка модели\"\"\"\n        load_path = Path(path)\n        \n        # Загружаем конфиг\n        config_path = load_path / \"config.json\"\n        with open(config_path, 'r') as f:\n            config_dict = json.load(f)\n        \n        config = EmbeddingConfig(**config_dict)\n        \n        # Создаем экземпляр\n        instance = cls(config=config)\n        \n        # Загружаем модель\n        model_path = load_path / \"bm25_model.pkl\"\n        if model_path.exists():\n            with open(model_path, 'rb') as f:\n                model_data = pickle.load(f)\n                instance.bm25 = model_data['bm25']\n                instance.vocabulary_size = model_data['vocabulary_size']\n                instance.language = model_data['language']\n                instance.max_features = model_data['max_features']\n        \n        return instance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:58:40.825243Z","iopub.execute_input":"2026-01-22T14:58:40.825571Z","iopub.status.idle":"2026-01-22T14:58:43.755971Z","shell.execute_reply.started":"2026-01-22T14:58:40.825549Z","shell.execute_reply":"2026-01-22T14:58:43.755195Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm.auto import tqdm\n\nclass DenseEmbeddingGenerator(BaseEmbeddingGenerator):\n    \"\"\"Генератор dense эмбеддингов\"\"\"\n    \n    def __init__(self,\n                 model_name: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n                 device: Optional[str] = None,\n                 normalize: bool = True,\n                 config: EmbeddingConfig = None):\n        super().__init__(config)\n        \n        self.model_name = model_name\n        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n        self.normalize = normalize\n        \n        # Ленивая загрузка модели\n        self._model = None\n        self.embedding_dim = 0\n    \n    @property\n    def model(self) -> SentenceTransformer:\n        \"\"\"Ленивая загрузка модели\"\"\"\n        if self._model is None:\n            print(f\"Загрузка dense модели: {self.model_name}\")\n            \n            # Освобождаем память перед загрузкой\n            self._free_memory()\n            \n            self._model = SentenceTransformer(\n                self.model_name,\n                device=self.device\n            )\n            \n            # Получаем размерность эмбеддингов\n            test_embedding = self._model.encode([\"test\"], \n                                               convert_to_numpy=True)\n            self.embedding_dim = test_embedding.shape[1]\n            \n            print(f\"✓ Модель загружена. Размерность эмбеддингов: {self.embedding_dim}\")\n        \n        return self._model\n    \n    def _free_memory(self):\n        \"\"\"Освобождение памяти\"\"\"\n        gc.collect()\n        if self.device == 'cuda' and torch.cuda.is_available():\n            torch.cuda.empty_cache()\n    \n    def fit(self, texts: List[str]) -> 'DenseEmbeddingGenerator':\n        \"\"\"Для dense моделей fit не требуется (но нужен для интерфейса)\"\"\"\n        print(\"Dense модели не требуют обучения на данных\")\n        return self\n    \n    def transform(self, texts: List[str], \n                  save_to_file: Optional[str] = None,\n                  show_progress: bool = True) -> np.ndarray:\n        \"\"\"Преобразование текстов в dense эмбеддинги\"\"\"\n        print(f\"Генерация dense эмбеддингов для {len(texts)} текстов...\")\n        \n        # Для очень больших данных используем memory-mapped файлы\n        if len(texts) > 50000 and self.config.use_mmap:\n            return self._transform_large_mmap(texts, save_to_file, show_progress)\n        \n        # Для средних данных используем батчевую обработку\n        if len(texts) > 1000:\n            return self._transform_batched(texts, save_to_file, show_progress)\n        \n        # Для небольших данных\n        return self._transform_small(texts, save_to_file, show_progress)\n    \n    def _transform_small(self, texts: List[str], \n                        save_to_file: Optional[str],\n                        show_progress: bool) -> np.ndarray:\n        \"\"\"Обработка небольших данных\"\"\"\n        embeddings = self.model.encode(\n            texts,\n            batch_size=self.config.batch_size,\n            show_progress_bar=show_progress,\n            convert_to_numpy=True,\n            normalize_embeddings=self.normalize\n        )\n        \n        if save_to_file:\n            np.save(save_to_file, embeddings)\n            print(f\"✓ Эмбеддинги сохранены в {save_to_file}\")\n        \n        return embeddings\n    \n    def _transform_batched(self, texts: List[str], \n                          save_to_file: Optional[str],\n                          show_progress: bool) -> np.ndarray:\n        \"\"\"Батчевая обработка средних данных\"\"\"\n        print(\"Используем батчевую обработку...\")\n        \n        all_embeddings = []\n        batch_size = self.config.batch_size\n        \n        # Прогресс-бар\n        if show_progress:\n            pbar = tqdm(total=len(texts), desc=\"Генерация эмбеддингов\")\n        \n        for i in range(0, len(texts), batch_size):\n            batch_texts = texts[i:i + batch_size]\n            \n            # Кодируем батч\n            batch_emb = self.model.encode(\n                batch_texts,\n                batch_size=batch_size,\n                show_progress_bar=False,\n                convert_to_numpy=True,\n                normalize_embeddings=self.normalize\n            )\n            \n            all_embeddings.append(batch_emb)\n            \n            if show_progress:\n                pbar.update(len(batch_texts))\n            \n            # Периодически проверяем память\n            if i % (batch_size * 10) == 0:\n                self._check_memory_usage()\n                gc.collect()\n        \n        if show_progress:\n            pbar.close()\n        \n        # Объединяем все батчи\n        embeddings = np.vstack(all_embeddings)\n        \n        if save_to_file:\n            np.save(save_to_file, embeddings)\n            print(f\"✓ Эмбеддинги сохранены в {save_to_file}\")\n        \n        return embeddings\n    \n    def _transform_large_mmap(self, texts: List[str], \n                             save_to_file: Optional[str],\n                             show_progress: bool) -> np.ndarray:\n        \"\"\"Обработка очень больших данных с memory-mapped файлами\"\"\"\n        print(\"Используем memory-mapped файлы для больших данных...\")\n        \n        if not save_to_file:\n            raise ValueError(\"Для больших данных требуется указать save_to_file\")\n        \n        # Создаем memory-mapped файл\n        total_samples = len(texts)\n        mmap_file = np.memmap(\n            save_to_file,\n            dtype=self.config.dtype,\n            mode='w+',\n            shape=(total_samples, self.embedding_dim)\n        )\n        \n        batch_size = self.config.batch_size\n        \n        # Прогресс-бар\n        if show_progress:\n            pbar = tqdm(total=total_samples, desc=\"Генерация эмбеддингов\")\n        \n        for i in range(0, total_samples, batch_size):\n            batch_texts = texts[i:i + batch_size]\n            \n            # Кодируем батч\n            batch_emb = self.model.encode(\n                batch_texts,\n                batch_size=batch_size,\n                show_progress_bar=False,\n                convert_to_numpy=True,\n                normalize_embeddings=self.normalize\n            )\n            \n            # Записываем в memory-mapped файл\n            mmap_file[i:i + len(batch_texts)] = batch_emb\n            \n            if show_progress:\n                pbar.update(len(batch_texts))\n            \n            # Очищаем память\n            del batch_emb\n            if i % (batch_size * 20) == 0:\n                self._check_memory_usage()\n                gc.collect()\n                if self.device == 'cuda':\n                    torch.cuda.empty_cache()\n        \n        if show_progress:\n            pbar.close()\n        \n        # Сохраняем изменения\n        mmap_file.flush()\n        \n        print(f\"✓ Эмбеддинги сохранены в {save_to_file}\")\n        \n        # Возвращаем как обычный numpy array (только для чтения)\n        return np.load(save_to_file, mmap_mode='r')\n    \n    def fit_transform(self, texts: List[str], \n                     save_to_file: Optional[str] = None,\n                     show_progress: bool = True) -> np.ndarray:\n        \"\"\"Обучение и преобразование\"\"\"\n        self.fit(texts)\n        return self.transform(texts, save_to_file, show_progress)\n    \n    def save(self, path: str) -> None:\n        \"\"\"Сохранение конфигурации модели\"\"\"\n        super().save(path)\n        save_path = Path(path)\n        \n        # Сохраняем информацию о модели\n        model_info = {\n            'model_name': self.model_name,\n            'device': self.device,\n            'normalize': self.normalize,\n            'embedding_dim': self.embedding_dim\n        }\n        \n        model_info_path = save_path / \"model_info.json\"\n        with open(model_info_path, 'w') as f:\n            json.dump(model_info, f)\n    \n    @classmethod\n    def load(cls, path: str) -> 'DenseEmbeddingGenerator':\n        \"\"\"Загрузка конфигурации модели\"\"\"\n        load_path = Path(path)\n        \n        # Загружаем конфиг\n        config_path = load_path / \"config.json\"\n        with open(config_path, 'r') as f:\n            config_dict = json.load(f)\n        \n        config = EmbeddingConfig(**config_dict)\n        \n        # Загружаем информацию о модели\n        model_info_path = load_path / \"model_info.json\"\n        with open(model_info_path, 'r') as f:\n            model_info = json.load(f)\n        \n        # Создаем экземпляр\n        instance = cls(\n            model_name=model_info['model_name'],\n            device=model_info['device'],\n            normalize=model_info['normalize'],\n            config=config\n        )\n        \n        instance.embedding_dim = model_info['embedding_dim']\n        \n        return instance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:58:43.756947Z","iopub.execute_input":"2026-01-22T14:58:43.757307Z","iopub.status.idle":"2026-01-22T14:59:14.093125Z","shell.execute_reply.started":"2026-01-22T14:58:43.757286Z","shell.execute_reply":"2026-01-22T14:59:14.092300Z"}},"outputs":[{"name":"stderr","text":"2026-01-22 14:58:56.834437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769093937.036216      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769093937.097086      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769093937.566004      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769093937.566050      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769093937.566053      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769093937.566055      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class EmbeddingFactory:\n    \"\"\"Фабрика для создания и управления эмбеддингами\"\"\"\n    \n    @staticmethod\n    def create_sparse_generator(config: Dict[str, Any] = None) -> SparseEmbeddingGenerator:\n        \"\"\"Создание sparse генератора\"\"\"\n        default_config = {\n            'language': 'russian',\n            'use_stopwords': True,\n            'use_stemming': False,\n            'max_features': 50000,\n            'bm25_k1': 1.5,\n            'bm25_b': 0.75,\n            'config': EmbeddingConfig()\n        }\n        \n        if config:\n            default_config.update(config)\n        \n        return SparseEmbeddingGenerator(\n            language=default_config['language'],\n            use_stopwords=default_config['use_stopwords'],\n            use_stemming=default_config['use_stemming'],\n            max_features=default_config['max_features'],\n            bm25_k1=default_config['bm25_k1'],\n            bm25_b=default_config['bm25_b'],\n            config=default_config['config']\n        )\n    \n    @staticmethod\n    def create_dense_generator(config: Dict[str, Any] = None) -> DenseEmbeddingGenerator:\n        \"\"\"Создание dense генератора\"\"\"\n        default_config = {\n            'model_name': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n            'device': None,\n            'normalize': True,\n            'config': EmbeddingConfig(batch_size=32)\n        }\n        \n        if config:\n            default_config.update(config)\n        \n        return DenseEmbeddingGenerator(\n            model_name=default_config['model_name'],\n            device=default_config['device'],\n            normalize=default_config['normalize'],\n            config=default_config['config']\n        )\n    \n    @staticmethod\n    def create_hybrid_pipeline(sparse_config: Dict[str, Any] = None,\n                              dense_config: Dict[str, Any] = None) -> Dict:\n        \"\"\"Создание пайплайна для гибридных эмбеддингов\"\"\"\n        return {\n            'sparse': EmbeddingFactory.create_sparse_generator(sparse_config),\n            'dense': EmbeddingFactory.create_dense_generator(dense_config)\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:59:14.097246Z","iopub.execute_input":"2026-01-22T14:59:14.097563Z","iopub.status.idle":"2026-01-22T14:59:14.104872Z","shell.execute_reply.started":"2026-01-22T14:59:14.097530Z","shell.execute_reply":"2026-01-22T14:59:14.104122Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"with open('/kaggle/input/crunch/techcrunch_ai_5488_articles_20260112_1535.json', 'r', encoding='utf-8') as f:\n    articles = json.load(f)\n\ntexts = [article['text'] for article in articles]\ntexts_clean = [clean_text_for_embedding(text) for text in texts]\nprint(f\"Загружено {len(texts)} статей\")\n\n# 2. Конфигурация\nsparse_config = {\n    'language': 'russian',\n    'max_features': 30000,\n    'use_stopwords': True,\n    'config': EmbeddingConfig(\n        batch_size=100,\n        use_mmap=True,\n        max_memory_gb=8.0\n    )\n}\n# 'intfloat/multilingual-e5-large-instruct'\nmodel_name = \"Qwen/Qwen3-Embedding-0.6B\"\ndense_config = {\n    'model_name': model_name,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    #'device': 'cpu',\n    'config': EmbeddingConfig(\n        batch_size=2,\n        use_mmap=True,\n        max_memory_gb=4.0\n    )\n}\n\ndense_gen = EmbeddingFactory.create_dense_generator(dense_config)\ndense_file = \"/kaggle/working/dense_embeddings.npy\"\n        \ndense_embeddings = dense_gen.fit_transform(\n    texts_clean,\n    save_to_file=dense_file,\n    show_progress=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T15:07:36.891634Z","iopub.execute_input":"2026-01-22T15:07:36.892258Z","iopub.status.idle":"2026-01-22T15:35:41.815095Z","shell.execute_reply.started":"2026-01-22T15:07:36.892231Z","shell.execute_reply":"2026-01-22T15:35:41.814486Z"}},"outputs":[{"name":"stdout","text":"Загружено 5488 статей\nDense модели не требуют обучения на данных\nГенерация dense эмбеддингов для 5488 текстов...\nИспользуем батчевую обработку...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Генерация эмбеддингов:   0%|          | 0/5488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e35b41673ff44519e2c0822c890d56e"}},"metadata":{}},{"name":"stdout","text":"Загрузка dense модели: Qwen/Qwen3-Embedding-0.6B\n✓ Модель загружена. Размерность эмбеддингов: 1024\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.33 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.34 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.35 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.36 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n⚠️ Предупреждение: Использовано 8.37 GB памяти (лимит: 4.0 GB)\n✓ Эмбеддинги сохранены в /kaggle/working/dense_embeddings.npy\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import json\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nimport torch\nfrom typing import List, Dict, Set\nfrom sklearn.preprocessing import normalize\nfrom datetime import datetime\n\n\nwith open('/kaggle/input/crunch/techcrunch_ai_5488_articles_20260112_1535.json', 'r', encoding='utf-8') as f:\n    articles = json.load(f)\nprint(f\"Статей: {len(articles)}\")\n\nwith open('/kaggle/input/crunch2/questions.json', 'r', encoding='utf-8') as f:\n    questions = json.load(f)\nprint(f\"Вопросов: {len(questions)}\")\n\narticle_id_to_idx = {}\narticle_titles = []\nfor idx, article in enumerate(articles):\n    article_id = article.get('id', str(idx))\n    article_id_to_idx[article_id] = idx\n    article_titles.append(article.get('title', ''))\n\ndense_file = \"/kaggle/working/dense_embeddings.npy\"\ndense_embeddings = np.load(dense_file)\nprint(f\"Эмбеддинги: {dense_embeddings.shape}\")\n\n# Создаем эмбеддинги для названий\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = SentenceTransformer(model_name, device=device)\n\ntitle_embeddings = model.encode(\n    article_titles,\n    batch_size=32,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\nprint(f\"Эмбеддинги названий: {title_embeddings.shape}\")\n\n# Нормализуем эмбеддинги\narticle_embeddings_norm = normalize(dense_embeddings)\ntitle_embeddings_norm = normalize(title_embeddings)\n\ndef enhanced_dense_search(query: str, k: int = 10, \n                         text_weight: float = 0.7,\n                         title_weight: float = 0.3) -> List[str]:\n    \"\"\"\n    Улучшенный поиск с учетом текста и названий статей\n    \n    Args:\n        query: текст запроса\n        k: количество результатов\n        text_weight: вес текста статьи (0-1)\n        title_weight: вес названия статьи (0-1)\n    \"\"\"\n    # Получаем эмбеддинг запроса\n    query_emb = model.encode(\n        query,\n        convert_to_numpy=True,\n        normalize_embeddings=True,\n        show_progress_bar=False\n    )\n    \n    # Поиск по тексту статей\n    text_similarities = query_emb @ article_embeddings_norm.T\n    \n    # Поиск по названиям статей\n    title_similarities = query_emb @ title_embeddings_norm.T\n    \n    # Комбинируем результаты с весами\n    combined_scores = (text_weight * text_similarities + \n                      title_weight * title_similarities)\n    \n    # Топ-K индексов\n    top_indices = np.argsort(-combined_scores)[:k]\n    \n    # Преобразуем индексы в ID\n    top_ids = []\n    for idx in top_indices:\n        # Ищем ID по индексу\n        for article_id, article_idx in article_id_to_idx.items():\n            if article_idx == idx:\n                top_ids.append(article_id)\n                break\n    \n    return top_ids\n    \ndef enhanced_time_dense_search(\n    query: str, \n    k: int = 10, \n    text_weight: float = 0.6,\n    title_weight: float = 0.2,\n    recency_weight: float = 0.2,\n    time_decay_days: int = 365  # Статьи старше года получают минимальный буст\n) -> List[str]:\n    \"\"\"\n    Улучшенный поиск с учетом текста, названий и актуальности статей\n    \"\"\"\n    # Получаем эмбеддинг запроса\n    query_emb = model.encode(\n        query,\n        convert_to_numpy=True,\n        normalize_embeddings=True,\n        show_progress_bar=False\n    )\n    \n    # Поиск по тексту статей\n    text_similarities = query_emb @ article_embeddings_norm.T\n    \n    # Поиск по названиям статей\n    title_similarities = query_emb @ title_embeddings_norm.T\n    \n    # Рассчитываем временной скор\n    current_time = datetime.now()\n    time_scores = []\n    \n    for article in articles:\n        try:\n            pub_time = datetime.fromisoformat(article.get('published_time', '2020-01-01'))\n            days_diff = (current_time - pub_time).days\n            # Экспоненциальный затухающий буст (больше для свежих статей)\n            time_score = np.exp(-days_diff / time_decay_days)\n        except:\n            time_score = 0.1  # Минимальный скор для статей без даты\n        \n        time_scores.append(time_score)\n    \n    time_scores = np.array(time_scores)\n    time_scores = time_scores / time_scores.max()  # Нормализуем к [0, 1]\n    \n    # Комбинируем результаты\n    combined_scores = (\n        text_weight * text_similarities + \n        title_weight * title_similarities +\n        recency_weight * time_scores\n    )\n    \n    # Топ-K индексов\n    top_indices = np.argsort(-combined_scores)[:k]\n    \n    # Преобразуем индексы в ID\n    top_ids = []\n    for idx in top_indices:\n        for article_id, article_idx in article_id_to_idx.items():\n            if article_idx == idx:\n                top_ids.append(article_id)\n                break\n    \n    return top_ids\n    \ndef basic_dense_search(query: str, k: int = 10) -> List[str]:\n    \"\"\"Только по тексту статей\"\"\"\n    query_emb = model.encode(\n        query,\n        convert_to_numpy=True,\n        normalize_embeddings=True,\n        show_progress_bar=False\n    )\n    \n    similarities = query_emb @ article_embeddings_norm.T\n    top_indices = np.argsort(-similarities)[:k]\n    \n    top_ids = []\n    for idx in top_indices:\n        for article_id, article_idx in article_id_to_idx.items():\n            if article_idx == idx:\n                top_ids.append(article_id)\n                break\n    \n    return top_ids\n\n# 4. Функция оценки\ndef evaluate_search(search_func, k_values=[1, 3, 5, 10]):\n    \"\"\"Оценка поиска с выводом метрик и деталей\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(\"ОЦЕНКА ПОИСКА ПО DENSE ЭМБЕДДИНГАМ\")\n    print(f\"{'='*60}\")\n    \n    results = []\n    \n    # Для каждого K считаем метрики\n    for k in k_values:\n        print(f\"\\nТОП-{k} РЕЗУЛЬТАТЫ:\")\n        print(\"-\" * 80)\n        \n        total_precision = 0\n        total_recall = 0\n        total_hit = 0\n        total_mrr = 0\n        valid_queries = 0\n        \n        # Обрабатываем каждый вопрос\n        for i, question_data in enumerate(questions):\n            query = question_data.get(\"question\", \"\")\n            correct_ids = set(question_data.get(\"id\", []))\n            \n            if not correct_ids:\n                continue\n            \n            # Поиск\n            found_ids = search_func(query, k=k)\n            \n            # Считаем метрики\n            correct_found = [id for id in found_ids if id in correct_ids]\n            \n            # Precision@K\n            precision = len(correct_found) / k if k > 0 else 0\n            \n            # Recall@K\n            recall = len(correct_found) / len(correct_ids) if correct_ids else 0\n            \n            # Hit Rate@K\n            hit = 1 if len(correct_found) > 0 else 0\n            \n            # MRR@K\n            mrr = 0\n            for rank, found_id in enumerate(found_ids, 1):\n                if found_id in correct_ids:\n                    mrr = 1.0 / rank\n                    break\n            \n            # Добавляем к итогам\n            total_precision += precision\n            total_recall += recall\n            total_hit += hit\n            total_mrr += mrr\n            valid_queries += 1\n            \n            # Выводим детали для первых 3 вопросов\n            if i < 3:\n                print(f\"\\nВопрос {i+1}: '{query[:50]}...'\")\n                print(f\"Правильные ID: {list(correct_ids)}\")\n                print(f\"Найденные ID: {found_ids}\")\n                print(f\"Совпадения: {correct_found}\")\n                print(f\"Несовпадения: {[id for id in found_ids if id not in correct_ids]}\")\n                print(f\"Precision@{k}: {precision:.3f}, Recall@{k}: {recall:.3f}\")\n        \n        # Средние метрики\n        if valid_queries > 0:\n            avg_precision = total_precision / valid_queries\n            avg_recall = total_recall / valid_queries\n            avg_hit = total_hit / valid_queries\n            avg_mrr = total_mrr / valid_queries\n            \n            # F1-score\n            f1 = 2 * avg_precision * avg_recall / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n            \n            print(f\"\\n{'='*80}\")\n            print(f\"ИТОГО ДЛЯ TOP-{k} (на {valid_queries} вопросах):\")\n            print(f\"  Precision@{k}: {avg_precision:.3f}\")\n            print(f\"  Recall@{k}:    {avg_recall:.3f}\")\n            print(f\"  F1@{k}:        {f1:.3f}\")\n            print(f\"  Hit Rate@{k}:  {avg_hit:.3f}\")\n            print(f\"  MRR@{k}:       {avg_mrr:.3f}\")\n            print(f\"{'='*80}\")\n            \n            results.append({\n                'k': k,\n                'precision': avg_precision,\n                'recall': avg_recall,\n                'f1': f1,\n                'hit_rate': avg_hit,\n                'mrr': avg_mrr\n            })\n    \n    return results\n\n\nevaluation_results = evaluate_search(enhanced_time_dense_search, k_values=[1, 3, 5, 10])\n\nprint(f\"\\n{'='*80}\")\nprint(\"СВОДНАЯ ТАБЛИЦА МЕТРИК\")\nprint(\"=\"*80)\nprint(f\"{'K':>4} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Hit Rate':>10} {'MRR':>10}\")\nprint(\"-\" * 80)\n\nfor res in evaluation_results:\n    print(f\"{res['k']:>4} \"\n          f\"{res['precision']:>10.3f} \"\n          f\"{res['recall']:>10.3f} \"\n          f\"{res['f1']:>10.3f} \"\n          f\"{res['hit_rate']:>10.3f} \"\n          f\"{res['mrr']:>10.3f}\")\n\nprint(\"=\"*80)\nsafe_model_name = model_name.replace('/', '_') \ntable_file = f\"/kaggle/working/metrics_{safe_model_name}.txt\"\nwith open(table_file, 'w', encoding='utf-8') as f:\n    # Простая таблица\n    f.write(\"Метрики поиска по dense эмбеддингам\\n\")\n    f.write(\"=\"*60 + \"\\n\")\n    f.write(\"K  Precision  Recall     F1        HitRate   MRR\\n\")\n    f.write(\"-\" * 60 + \"\\n\")\n    \n    for res in evaluation_results:\n        f.write(f\"{res['k']:2}  {res['precision']:8.3f}  {res['recall']:8.3f}  \"\n                f\"{res['f1']:8.3f}  {res['hit_rate']:8.3f}  {res['mrr']:8.3f}\\n\")\n    \n    f.write(\"=\"*60 + \"\\n\")\n\nprint(f\"Таблица сохранена в {table_file}\")\n\n# 7. Детальный анализ для всех вопросов (сохранение в файл)\nprint(\"\\nСОХРАНЕНИЕ ДЕТАЛЬНЫХ РЕЗУЛЬТАТОВ...\")\n\ndetailed_results = []\n\nfor i, question_data in enumerate(questions):\n    query = question_data.get(\"question\", \"\")\n    correct_ids = set(question_data.get(\"id\", []))\n    \n    if not correct_ids:\n        continue\n    \n    # Ищем для Top-5\n    found_ids = enhanced_time_dense_search(query, k=5)\n    \n    # Определяем совпадения\n    matches = [id for id in found_ids if id in correct_ids]\n    non_matches = [id for id in found_ids if id not in correct_ids]\n    \n    # Precision для этого запроса\n    precision_5 = len(matches) / 5 if found_ids else 0\n    \n    detailed_results.append({\n        'query_id': i + 1,\n        'query': query,\n        'correct_ids': list(correct_ids),\n        'found_ids': found_ids,\n        'matches': matches,\n        'non_matches': non_matches,\n        'precision_5': precision_5,\n        'num_matches': len(matches)\n    })\n    \n    # Выводим детали для первых 5 вопросов\n    if i < 5:\n        print(f\"\\nВопрос {i+1}:\")\n        print(f\"  Запрос: '{query[:60]}...'\")\n        print(f\"  Правильные ID: {list(correct_ids)}\")\n        print(f\"  Найденные ID: {found_ids}\")\n        print(f\"  ✓ Совпали: {matches}\")\n        print(f\"  ✗ Не совпали: {non_matches}\")\n        print(f\"  Precision@5: {precision_5:.3f}\")\n\nsafe_model_name = model_name.replace('/', '_') \noutput_file = f\"/kaggle/working/search_evaluation_details_{safe_model_name}.json\"\nwith open(output_file, 'w', encoding='utf-8') as f:\n    json.dump(detailed_results, f, indent=2, ensure_ascii=False)\n\nprint(f\"\\n✓ Детальные результаты сохранены в {output_file}\")\n\n# 8. Статистика совпадений\nprint(f\"\\n{'='*80}\")\nprint(\"СТАТИСТИКА СОВПАДЕНИЙ (Top-5)\")\nprint(\"=\"*80)\n\ntotal_questions = len([q for q in questions if q.get('id')])\ntotal_positions = total_questions * 5\ntotal_matches = sum(res['num_matches'] for res in detailed_results)\ntotal_non_matches = total_positions - total_matches\n\nprint(f\"Всего вопросов с ответами: {total_questions}\")\nprint(f\"Всего проверок (вопросов × Top-5): {total_positions}\")\nprint(f\"Всего совпадений: {total_matches}\")\nprint(f\"Всего несовпадений: {total_non_matches}\")\nprint(f\"Процент совпадений: {total_matches/total_positions*100:.1f}%\")\n\n# Распределение по количеству совпадений\nmatches_dist = {}\nfor res in detailed_results:\n    num_matches = res['num_matches']\n    matches_dist[num_matches] = matches_dist.get(num_matches, 0) + 1\n\nprint(f\"\\nРаспределение совпадений на вопрос:\")\nfor num in sorted(matches_dist.keys()):\n    count = matches_dist[num]\n    percentage = count / total_questions * 100\n    print(f\"  {num} совпадений: {count} вопросов ({percentage:.1f}%)\")\n\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T17:04:36.337167Z","iopub.execute_input":"2026-01-22T17:04:36.337489Z","iopub.status.idle":"2026-01-22T17:05:24.504253Z","shell.execute_reply.started":"2026-01-22T17:04:36.337463Z","shell.execute_reply":"2026-01-22T17:05:24.503584Z"}},"outputs":[{"name":"stdout","text":"Статей: 5488\nВопросов: 60\nЭмбеддинги: (5488, 1024)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/172 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72d7c255bae744f1b7011cfc4274089a"}},"metadata":{}},{"name":"stdout","text":"Эмбеддинги названий: (5488, 1024)\n\n============================================================\nОЦЕНКА ПОИСКА ПО DENSE ЭМБЕДДИНГАМ\n============================================================\n\nТОП-1 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\nПравильные ID: ['69e1be8c-f789-5de3-8c1a-c89f92639178', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНайденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c']\nСовпадения: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c']\nНесовпадения: []\nPrecision@1: 1.000, Recall@1: 0.200\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\nПравильные ID: ['7ab20568-f68c-5cfe-a657-14c93f76771c', '8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\nНайденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\nСовпадения: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\nНесовпадения: []\nPrecision@1: 1.000, Recall@1: 0.200\n\nВопрос 3: 'What's new in the Microsoft and Open AI race?...'\nПравильные ID: ['9cbbf332-c8d7-56c0-87e2-0a352d1f09c1', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'cae59663-09df-5005-a909-63a05a853e7f']\nНайденные ID: ['cae59663-09df-5005-a909-63a05a853e7f']\nСовпадения: ['cae59663-09df-5005-a909-63a05a853e7f']\nНесовпадения: []\nPrecision@1: 1.000, Recall@1: 0.333\n\n================================================================================\nИТОГО ДЛЯ TOP-1 (на 60 вопросах):\n  Precision@1: 0.333\n  Recall@1:    0.063\n  F1@1:        0.106\n  Hit Rate@1:  0.333\n  MRR@1:       0.333\n================================================================================\n\nТОП-3 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\nПравильные ID: ['69e1be8c-f789-5de3-8c1a-c89f92639178', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНайденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nСовпадения: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНесовпадения: []\nPrecision@3: 1.000, Recall@3: 0.600\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\nПравильные ID: ['7ab20568-f68c-5cfe-a657-14c93f76771c', '8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\nНайденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\nСовпадения: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7']\nНесовпадения: []\nPrecision@3: 1.000, Recall@3: 0.600\n\nВопрос 3: 'What's new in the Microsoft and Open AI race?...'\nПравильные ID: ['9cbbf332-c8d7-56c0-87e2-0a352d1f09c1', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'cae59663-09df-5005-a909-63a05a853e7f']\nНайденные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '3c7862bd-11ed-5227-8b33-2ea927f24bd0']\nСовпадения: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0']\nНесовпадения: ['26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nPrecision@3: 0.667, Recall@3: 0.667\n\n================================================================================\nИТОГО ДЛЯ TOP-3 (на 60 вопросах):\n  Precision@3: 0.256\n  Recall@3:    0.147\n  F1@3:        0.186\n  Hit Rate@3:  0.417\n  MRR@3:       0.369\n================================================================================\n\nТОП-5 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\nПравильные ID: ['69e1be8c-f789-5de3-8c1a-c89f92639178', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНайденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\nСовпадения: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\nНесовпадения: []\nPrecision@5: 1.000, Recall@5: 1.000\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\nПравильные ID: ['7ab20568-f68c-5cfe-a657-14c93f76771c', '8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\nНайденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\nСовпадения: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\nНесовпадения: []\nPrecision@5: 1.000, Recall@5: 1.000\n\nВопрос 3: 'What's new in the Microsoft and Open AI race?...'\nПравильные ID: ['9cbbf332-c8d7-56c0-87e2-0a352d1f09c1', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'cae59663-09df-5005-a909-63a05a853e7f']\nНайденные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'b94e436d-670f-567d-8fbd-c83fe965ce0f', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nСовпадения: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nНесовпадения: ['26a13d66-152b-5969-93e9-41e0b7b5c9aa', 'b94e436d-670f-567d-8fbd-c83fe965ce0f']\nPrecision@5: 0.600, Recall@5: 1.000\n\n================================================================================\nИТОГО ДЛЯ TOP-5 (на 60 вопросах):\n  Precision@5: 0.237\n  Recall@5:    0.213\n  F1@5:        0.224\n  Hit Rate@5:  0.533\n  MRR@5:       0.396\n================================================================================\n\nТОП-10 РЕЗУЛЬТАТЫ:\n--------------------------------------------------------------------------------\n\nВопрос 1: 'What are the features that GPT-5 can provide compa...'\nПравильные ID: ['69e1be8c-f789-5de3-8c1a-c89f92639178', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\nНайденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178', 'f7a16c3a-fe5c-56f9-86f3-cdc674dda9f6', 'c6cc8e9d-c7d4-5409-82ac-1a157ebca402', '0ea38ba7-739e-5bff-b4be-0f6c82b3146d', '99d641d9-f659-596e-a333-9fa306675c85', 'bdfb4d03-5752-57f5-beb5-c59a2c955fb8']\nСовпадения: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\nНесовпадения: ['f7a16c3a-fe5c-56f9-86f3-cdc674dda9f6', 'c6cc8e9d-c7d4-5409-82ac-1a157ebca402', '0ea38ba7-739e-5bff-b4be-0f6c82b3146d', '99d641d9-f659-596e-a333-9fa306675c85', 'bdfb4d03-5752-57f5-beb5-c59a2c955fb8']\nPrecision@10: 0.500, Recall@10: 1.000\n\nВопрос 2: 'What new technologies in processor manufacturing w...'\nПравильные ID: ['7ab20568-f68c-5cfe-a657-14c93f76771c', '8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\nНайденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c', '9376fa88-18e4-5ec3-8577-4886291ab8e8', 'c6cf1538-226d-59f8-8b1d-66abd5a51f69', 'd5fb6539-585c-5763-a56f-af4cb037d569', '171ffdd4-e1a9-5d3e-b7b1-2fcb6473f78e', 'ea39e122-4f2c-5410-8aaa-0b52cddbed12']\nСовпадения: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\nНесовпадения: ['9376fa88-18e4-5ec3-8577-4886291ab8e8', 'c6cf1538-226d-59f8-8b1d-66abd5a51f69', 'd5fb6539-585c-5763-a56f-af4cb037d569', '171ffdd4-e1a9-5d3e-b7b1-2fcb6473f78e', 'ea39e122-4f2c-5410-8aaa-0b52cddbed12']\nPrecision@10: 0.500, Recall@10: 1.000\n\nВопрос 3: 'What's new in the Microsoft and Open AI race?...'\nПравильные ID: ['9cbbf332-c8d7-56c0-87e2-0a352d1f09c1', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'cae59663-09df-5005-a909-63a05a853e7f']\nНайденные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'b94e436d-670f-567d-8fbd-c83fe965ce0f', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1', 'b8f70442-b2cf-5a86-9579-cb286d041c4d', 'af2ed871-dcb1-536c-94a5-600fb6b95df1', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '625a48b4-c174-51c9-8f43-3741db1fab01']\nСовпадения: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\nНесовпадения: ['26a13d66-152b-5969-93e9-41e0b7b5c9aa', 'b94e436d-670f-567d-8fbd-c83fe965ce0f', 'b8f70442-b2cf-5a86-9579-cb286d041c4d', 'af2ed871-dcb1-536c-94a5-600fb6b95df1', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '625a48b4-c174-51c9-8f43-3741db1fab01']\nPrecision@10: 0.300, Recall@10: 1.000\n\n================================================================================\nИТОГО ДЛЯ TOP-10 (на 60 вопросах):\n  Precision@10: 0.170\n  Recall@10:    0.297\n  F1@10:        0.216\n  Hit Rate@10:  0.650\n  MRR@10:       0.412\n================================================================================\n\n================================================================================\nСВОДНАЯ ТАБЛИЦА МЕТРИК\n================================================================================\n   K  Precision     Recall         F1   Hit Rate        MRR\n--------------------------------------------------------------------------------\n   1      0.333      0.063      0.106      0.333      0.333\n   3      0.256      0.147      0.186      0.417      0.369\n   5      0.237      0.213      0.224      0.533      0.396\n  10      0.170      0.297      0.216      0.650      0.412\n================================================================================\nТаблица сохранена в /kaggle/working/metrics_Qwen_Qwen3-Embedding-0.6B.txt\n\nСОХРАНЕНИЕ ДЕТАЛЬНЫХ РЕЗУЛЬТАТОВ...\n\nВопрос 1:\n  Запрос: 'What are the features that GPT-5 can provide compared to GPT...'\n  Правильные ID: ['69e1be8c-f789-5de3-8c1a-c89f92639178', '81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '13ed2979-8642-5bcd-809d-8897177f0c3d', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa']\n  Найденные ID: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\n  ✓ Совпали: ['81dd3690-0641-5fbd-b2a0-c2ae95bb9a0c', '9a0df61d-4783-51f2-acc4-e66f52cd0813', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '13ed2979-8642-5bcd-809d-8897177f0c3d', '69e1be8c-f789-5de3-8c1a-c89f92639178']\n  ✗ Не совпали: []\n  Precision@5: 1.000\n\nВопрос 2:\n  Запрос: 'What new technologies in processor manufacturing will domina...'\n  Правильные ID: ['7ab20568-f68c-5cfe-a657-14c93f76771c', '8b678d66-56a3-55b5-9eb0-bcf11368c852', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', 'ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7']\n  Найденные ID: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\n  ✓ Совпали: ['ed6f3aa0-07bc-519e-b76a-aa79dc04b0a7', 'eb17f839-22c4-5c8e-ab21-32f423d32aa2', '821d70b8-720d-5430-8fe5-3f679ffdfdc7', '8b678d66-56a3-55b5-9eb0-bcf11368c852', '7ab20568-f68c-5cfe-a657-14c93f76771c']\n  ✗ Не совпали: []\n  Precision@5: 1.000\n\nВопрос 3:\n  Запрос: 'What's new in the Microsoft and Open AI race?...'\n  Правильные ID: ['9cbbf332-c8d7-56c0-87e2-0a352d1f09c1', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'cae59663-09df-5005-a909-63a05a853e7f']\n  Найденные ID: ['cae59663-09df-5005-a909-63a05a853e7f', '26a13d66-152b-5969-93e9-41e0b7b5c9aa', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', 'b94e436d-670f-567d-8fbd-c83fe965ce0f', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\n  ✓ Совпали: ['cae59663-09df-5005-a909-63a05a853e7f', '3c7862bd-11ed-5227-8b33-2ea927f24bd0', '9cbbf332-c8d7-56c0-87e2-0a352d1f09c1']\n  ✗ Не совпали: ['26a13d66-152b-5969-93e9-41e0b7b5c9aa', 'b94e436d-670f-567d-8fbd-c83fe965ce0f']\n  Precision@5: 0.600\n\nВопрос 4:\n  Запрос: 'How are multimodal models (text, image, video, and audio) ev...'\n  Правильные ID: ['55421df0-b7c0-5005-a23f-22ff83a6f4b7', 'f9aa5688-9785-54a4-b377-80f0db840d10', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '33ca7341-8844-536a-bf4f-ff3cdfed03c5', 'd8240b33-2ec1-5da5-ad17-5cc2dfbf8b8c']\n  Найденные ID: ['d8240b33-2ec1-5da5-ad17-5cc2dfbf8b8c', 'f9aa5688-9785-54a4-b377-80f0db840d10', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '33ca7341-8844-536a-bf4f-ff3cdfed03c5', '55421df0-b7c0-5005-a23f-22ff83a6f4b7']\n  ✓ Совпали: ['d8240b33-2ec1-5da5-ad17-5cc2dfbf8b8c', 'f9aa5688-9785-54a4-b377-80f0db840d10', '99a179ed-b2d9-5604-a458-5c19ee8839a0', '33ca7341-8844-536a-bf4f-ff3cdfed03c5', '55421df0-b7c0-5005-a23f-22ff83a6f4b7']\n  ✗ Не совпали: []\n  Precision@5: 1.000\n\nВопрос 5:\n  Запрос: 'What are AI agent systems, and how do they change the way au...'\n  Правильные ID: ['9c0a4b8e-704f-52f2-92ed-cc0c97da2c5d', 'fc60f3bc-4d99-595a-96bb-89b1afb489de', '0ccf9b82-2a5d-522a-9eb2-c12eb8839587']\n  Найденные ID: ['9c0a4b8e-704f-52f2-92ed-cc0c97da2c5d', '0ccf9b82-2a5d-522a-9eb2-c12eb8839587', 'fc60f3bc-4d99-595a-96bb-89b1afb489de', 'f837a58a-1a05-5673-885d-8eb9255426e4', 'df809136-d2b5-56a1-8300-0796991cc6e3']\n  ✓ Совпали: ['9c0a4b8e-704f-52f2-92ed-cc0c97da2c5d', '0ccf9b82-2a5d-522a-9eb2-c12eb8839587', 'fc60f3bc-4d99-595a-96bb-89b1afb489de']\n  ✗ Не совпали: ['f837a58a-1a05-5673-885d-8eb9255426e4', 'df809136-d2b5-56a1-8300-0796991cc6e3']\n  Precision@5: 0.600\n\n✓ Детальные результаты сохранены в /kaggle/working/search_evaluation_details_Qwen_Qwen3-Embedding-0.6B.json\n\n================================================================================\nСТАТИСТИКА СОВПАДЕНИЙ (Top-5)\n================================================================================\nВсего вопросов с ответами: 60\nВсего проверок (вопросов × Top-5): 300\nВсего совпадений: 71\nВсего несовпадений: 229\nПроцент совпадений: 23.7%\n\nРаспределение совпадений на вопрос:\n  0 совпадений: 28 вопросов (46.7%)\n  1 совпадений: 13 вопросов (21.7%)\n  2 совпадений: 9 вопросов (15.0%)\n  3 совпадений: 4 вопросов (6.7%)\n  4 совпадений: 2 вопросов (3.3%)\n  5 совпадений: 4 вопросов (6.7%)\n================================================================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"found_ids = enhanced_time_dense_search(\"What are AI agent systems, and how do they change the way automation is approached?\", k=5)\nprint(found_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T16:34:48.180895Z","iopub.execute_input":"2026-01-22T16:34:48.181185Z","iopub.status.idle":"2026-01-22T16:34:48.242217Z","shell.execute_reply.started":"2026-01-22T16:34:48.181161Z","shell.execute_reply":"2026-01-22T16:34:48.241676Z"}},"outputs":[{"name":"stdout","text":"['9c0a4b8e-704f-52f2-92ed-cc0c97da2c5d', '0ccf9b82-2a5d-522a-9eb2-c12eb8839587', 'fc60f3bc-4d99-595a-96bb-89b1afb489de', 'f837a58a-1a05-5673-885d-8eb9255426e4', 'df809136-d2b5-56a1-8300-0796991cc6e3']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Проверка на размеченных данных","metadata":{}},{"cell_type":"code","source":"class SearchEvaluator:\n    \"\"\"\n    Оценка качества поиска с правильными метриками\n    \"\"\"\n    \n    def __init__(self, questions_path, article_id_to_index):\n        with open(questions_path, 'r') as f:\n            self.questions = json.load(f)\n        self.article_id_to_index = article_id_to_index\n    \n    def evaluate_method(self, search_function, method_name, k_values=[1, 3, 5, 10]):\n        \"\"\"\n        Оценка метода поиска с разными значениями K\n        \n        Args:\n            search_function: функция поиска (query, k) -> список результатов\n            method_name: название метода\n            k_values: значения K для расчета Precision@K, Recall@K и т.д.\n        \"\"\"\n        print(f\"\\n{'='*60}\")\n        print(f\"ОЦЕНКА МЕТОДА: {method_name}\")\n        print(f\"{'='*60}\")\n        \n        results = {\n            \"method\": method_name,\n            \"total_queries\": len(self.questions),\n            \"metrics\": {}\n        }\n        \n        # Инициализируем метрики для каждого K\n        for k in k_values:\n            results[\"metrics\"][k] = {\n                \"precision\": [],\n                \"recall\": [],\n                \"f1\": [],\n                \"hit_rate\": [],\n                \"mrr\": [],\n                \"ndcg\": []  # Нормализованный дисконтированный кумулятивный выигрыш\n            }\n        \n        # Обрабатываем каждый запрос\n        for query_idx, query_data in enumerate(self.questions):\n            query = query_data.get(\"question\", \"\")\n            relevant_ids = set(query_data.get(\"id\", []))\n            \n            if not relevant_ids:\n                continue  # Пропускаем вопросы без релевантных статей\n            \n            # Получаем результаты поиска для максимального K\n            max_k = max(k_values)\n            try:\n                search_results = search_function(query, k=max_k)\n            except Exception as e:\n                print(f\"  Ошибка для запроса {query_idx+1}: {e}\")\n                continue\n            \n            # Для каждого значения K считаем метрики\n            for k in k_values:\n                # Берем только топ-K результатов\n                top_k_results = search_results[:k] if len(search_results) > k else search_results\n                \n                # Считаем метрики для этого K\n                metrics = self._calculate_metrics_for_k(top_k_results, relevant_ids, k)\n                \n                # Добавляем к общим результатам\n                for metric_name, value in metrics.items():\n                    results[\"metrics\"][k][metric_name].append(value)\n            \n            # Прогресс\n            if (query_idx + 1) % 10 == 0:\n                print(f\"  Обработано {query_idx + 1}/{len(self.questions)} запросов\")\n        \n        # Усредняем метрики по всем запросам\n        print(f\"\\nРЕЗУЛЬТАТЫ ДЛЯ МЕТОДА '{method_name}':\")\n        print(\"-\" * 80)\n        \n        summary_table = []\n        for k in k_values:\n            avg_metrics = {}\n            for metric_name in results[\"metrics\"][k]:\n                values = results[\"metrics\"][k][metric_name]\n                if values:  # Если есть значения\n                    avg_metrics[metric_name] = np.mean(values)\n                else:\n                    avg_metrics[metric_name] = 0.0\n            \n            summary_table.append({\n                \"K\": k,\n                \"Precision\": f\"{avg_metrics['precision']:.3f}\",\n                \"Recall\": f\"{avg_metrics['recall']:.3f}\",\n                \"F1\": f\"{avg_metrics['f1']:.3f}\",\n                \"Hit Rate\": f\"{avg_metrics['hit_rate']:.3f}\",\n                \"MRR\": f\"{avg_metrics['mrr']:.3f}\"\n            })\n            \n            # Выводим для Top-5 более подробно\n            if k == 5:\n                print(f\"Top-{k} Performance:\")\n                print(f\"  Precision@{k}: {avg_metrics['precision']:.3f} - доля релевантных в топ-{k}\")\n                print(f\"  Recall@{k}:    {avg_metrics['recall']:.3f} - доля найденных релевантных\")\n                print(f\"  F1@{k}:        {avg_metrics['f1']:.3f} - баланс точности и полноты\")\n                print(f\"  Hit Rate@{k}:  {avg_metrics['hit_rate']:.3f} - вероятность найти хоть что-то\")\n                print(f\"  MRR@{k}:       {avg_metrics['mrr']:.3f} - качество ранжирования\")\n        \n        # Выводим таблицу\n        print(f\"\\nСводная таблица:\")\n        print(\"-\" * 80)\n        headers = [\"K\", \"Precision\", \"Recall\", \"F1\", \"Hit Rate\", \"MRR\"]\n        row_format = \"{:>4} {:>10} {:>10} {:>10} {:>10} {:>10}\"\n        print(row_format.format(*headers))\n        print(\"-\" * 80)\n        for row in summary_table:\n            print(row_format.format(\n                row[\"K\"], \n                row[\"Precision\"], \n                row[\"Recall\"], \n                row[\"F1\"], \n                row[\"Hit Rate\"], \n                row[\"MRR\"]\n            ))\n        \n        return results\n    \n    def _calculate_metrics_for_k(self, results, relevant_ids, k):\n        \"\"\"\n        Расчет метрик для топ-K результатов\n        \n        Args:\n            results: список результатов поиска (топ-K)\n            relevant_ids: множество ID релевантных статей\n            k: значение K (для нормализации)\n        \n        Returns:\n            Словарь с метриками\n        \"\"\"\n        # 1. Precision@K: доля релевантных в результатах\n        relevant_found = 0\n        for result in results:\n            if result[\"article\"][\"id\"] in relevant_ids:\n                relevant_found += 1\n        precision = relevant_found / len(results) if results else 0\n        \n        # 2. Recall@K: доля найденных релевантных от всех релевантных\n        recall = relevant_found / len(relevant_ids) if relevant_ids else 0\n        \n        # 3. F1@K: гармоническое среднее\n        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n        \n        # 4. Hit Rate@K: была ли найдена хоть одна релевантная статья\n        hit_rate = 1 if relevant_found > 0 else 0\n        \n        # 5. MRR@K: средняя обратная позиция первого релевантного результата\n        mrr = 0\n        for rank, result in enumerate(results, 1):\n            if result[\"article\"][\"id\"] in relevant_ids:\n                mrr = 1.0 / rank\n                break\n        \n        # 6. NDCG@K (опционально, более сложная метрика)\n        # Для простоты можно пропустить\n        \n        return {\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1\": f1,\n            \"hit_rate\": hit_rate,\n            \"mrr\": mrr\n        }\n    \n    def compare_methods(self, methods_dict, k_values=[1, 3, 5, 10]):\n        \"\"\"\n        Сравнение нескольких методов поиска\n        \n        Args:\n            methods_dict: словарь {название_метода: функция_поиска}\n            k_values: значения K для оценки\n        \"\"\"\n        print(\"\\n\" + \"=\"*80)\n        print(\"СРАВНИТЕЛЬНЫЙ АНАЛИЗ МЕТОДОВ ПОИСКА\")\n        print(\"=\"*80)\n        \n        all_results = {}\n        \n        for method_name, search_func in methods_dict.items():\n            results = self.evaluate_method(search_func, method_name, k_values)\n            all_results[method_name] = results\n        \n        # Ранжирование методов по F1@5\n        print(\"\\n\" + \"=\"*80)\n        print(\"РАНЖИРОВАНИЕ МЕТОДОВ ПО F1@5:\")\n        print(\"=\"*80)\n        \n        rankings = []\n        for method_name, results in all_results.items():\n            f1_at_5 = np.mean(results[\"metrics\"][5][\"f1\"]) if results[\"metrics\"][5][\"f1\"] else 0\n            precision_at_5 = np.mean(results[\"metrics\"][5][\"precision\"]) if results[\"metrics\"][5][\"precision\"] else 0\n            recall_at_5 = np.mean(results[\"metrics\"][5][\"recall\"]) if results[\"metrics\"][5][\"recall\"] else 0\n            \n            rankings.append({\n                \"Method\": method_name,\n                \"F1@5\": f1_at_5,\n                \"Precision@5\": precision_at_5,\n                \"Recall@5\": recall_at_5\n            })\n        \n        # Сортируем по F1@5\n        rankings.sort(key=lambda x: x[\"F1@5\"], reverse=True)\n        \n        # Выводим таблицу\n        print(\"\\nРейтинг методов (лучший → худший):\")\n        print(\"-\" * 80)\n        print(f\"{'Метод':<20} {'F1@5':<8} {'Precision@5':<12} {'Recall@5':<10}\")\n        print(\"-\" * 80)\n        for rank, item in enumerate(rankings, 1):\n            print(f\"{rank}. {item['Method']:<18} {item['F1@5']:.3f}    {item['Precision@5']:.3f}        {item['Recall@5']:.3f}\")\n        \n        return all_results\n\n\nevaluator = SearchEvaluator(\"/kaggle/input/crunch/questions.json\", article_id_to_index)\n\n# Определяем методы поиска\n# methods_to_test = {\n#    \"BM25\": lambda q, k: hybrid_search.search_by_bm25(q, k=k),\n#    \"Dense\": lambda q, k: hybrid_search.search_by_dense(q, k=k),\n#    \"Hybrid (α=0.3)\": lambda q, k: hybrid_search.hybrid_search(q, k=k, alpha=0.3),\n#    \"Hybrid (α=0.5)\": lambda q, k: hybrid_search.hybrid_search(q, k=k, alpha=0.5),\n#    \"Hybrid (α=0.7)\": lambda q, k: hybrid_search.hybrid_search(q, k=k, alpha=0.7)\n#}\nmethods_to_test = {\"Dense\": lambda q, k: hybrid_search.search_by_dense(q, k=k)}\n# Полная оценка\nfull_results = evaluator.compare_methods(methods_to_test, k_values=[1, 3, 5, 10])\n\n# Или быстрая оценка\nprint(\"\\n\" + \"=\"*60)\nprint(\"БЫСТРАЯ ОЦЕНКА (только Top-5)\")\nprint(\"=\"*60)\n\nsimple_evaluator = SimpleSearchEvaluator(\"/kaggle/input/crunch/questions.json\", article_id_to_index)\nquick_results = simple_evaluator.quick_compare(methods_to_test, k=5)\n\n# Анализ примеров\nprint(\"\\n\" + \"=\"*60)\nprint(\"АНАЛИЗ ПРИМЕРОВ РАБОТЫ ЛУЧШЕГО МЕТОДА\")\nprint(\"=\"*60)\n\nbest_method_name = max(quick_results.items(), key=lambda x: x[1]['f1'])[0]\nbest_search_func = methods_to_test[best_method_name]\n\n# Проанализируем несколько запросов\nprint(f\"\\nАнализ работы лучшего метода: {best_method_name}\")\nprint(\"-\" * 80)\n\nsample_queries = evaluator.questions[:10]  # Первые 3 запроса\n\nfor i, query_data in enumerate(sample_queries):\n    query = query_data.get(\"question\", \"\")\n    relevant_ids = set(query_data.get(\"id\", []))\n    \n    print(f\"\\nЗапрос {i+1}: '{query[:60]}...'\")\n    print(f\"Релевантные ID: {list(relevant_ids)[:3]}...\")\n    \n    try:\n        results = best_search_func(query, k=5)\n        print(f\"Найдено результатов: {len(results)}\")\n        \n        print(\"Топ-5 результатов:\")\n        for j, result in enumerate(results[:5]):\n            article_id = result[\"article\"][\"id\"]\n            is_relevant = \"✓\" if article_id in relevant_ids else \"✗\"\n            score_key = \"score\" if \"score\" in result else \"hybrid_score\"\n            score = result.get(score_key, 0)\n            \n            print(f\"  {j+1}. [{is_relevant}] {result['article']['title'][:50]}... (score: {score:.3f})\")\n        \n        # Считаем Precision@5 для этого запроса\n        relevant_found = sum(1 for r in results if r[\"article\"][\"id\"] in relevant_ids)\n        precision = relevant_found / len(results) if results else 0\n        print(f\"  Precision@5 для этого запроса: {precision:.3f} ({relevant_found}/{len(results)})\")\n        \n    except Exception as e:\n        print(f\"  Ошибка: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T13:36:29.764606Z","iopub.execute_input":"2026-01-21T13:36:29.764925Z","iopub.status.idle":"2026-01-21T13:36:29.791592Z","shell.execute_reply.started":"2026-01-21T13:36:29.764901Z","shell.execute_reply":"2026-01-21T13:36:29.790684Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/767589218.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSearchEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/crunch/questions.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_id_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;31m# Определяем методы поиска\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'article_id_to_index' is not defined"],"ename":"NameError","evalue":"name 'article_id_to_index' is not defined","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"# 5. Упрощенная оценка\nprint(\"\\n\" + \"=\"*60)\nprint(\"УПРОЩЕННАЯ ОЦЕНКА КАЧЕСТВА:\")\nprint(\"=\"*60)\n\n# Создаем простой evaluator\nclass SimpleEvaluator:\n    def __init__(self, questions_path, article_id_to_index):\n        with open(questions_path, 'r') as f:\n            self.questions = json.load(f)\n        self.article_id_to_index = article_id_to_index\n    \n    def evaluate(self, search_function, method_name, k=5):\n        print(f\"\\n{method_name} (Top-{k}):\")\n        \n        total_correct = 0\n        total_possible = 0\n        \n        for query_data in self.questions:\n            query = query_data[\"question\"]\n            relevant_ids = set(query_data.get(\"id\", []))\n            \n            if not relevant_ids:\n                continue\n            \n            try:\n                results = search_function(query, k=k)\n            except:\n                continue\n            \n            # Считаем сколько релевантных нашли\n            found_relevant = 0\n            for result in results:\n                if result[\"article\"][\"id\"] in relevant_ids:\n                    found_relevant += 1\n            \n            total_correct += found_relevant\n            total_possible += min(len(relevant_ids), k)\n        \n        accuracy = total_correct / total_possible if total_possible > 0 else 0\n        print(f\"  Найдено релевантных: {total_correct}/{total_possible}\")\n        print(f\"  Accuracy: {accuracy:.3f}\")\n        \n        return accuracy\n\n# Создаем mapping\narticle_id_to_index = {}\nfor idx, article in enumerate(results[\"articles\"]):\n    article_id_to_index[article[\"id\"]] = idx\n\nevaluator = SimpleEvaluator(\"/kaggle/input/crunch/questions.json\", article_id_to_index)\n\n# Инициализация поиска\nsearch_data = {\n    \"articles\": results[\"articles\"],\n    \"bm25_matrix\": results[\"bm25_matrix\"],\n    \"dense_embeddings\": results[\"dense_embeddings\"],\n    \"vocabulary\": results[\"vocabulary\"],\n    \"bm25_vectorizer_info\": results.get(\"bm25_vectorizer_info\", {})\n}\n\nhybrid_search = HybridSearch(search_data)\n\n# Оценка методов\nmethods = [\n    (\"BM25\", lambda q, k: hybrid_search.search_by_bm25(q, k)),\n    (\"Dense\", lambda q, k: hybrid_search.search_by_dense(q, k)),\n    (\"Hybrid α=0.3\", lambda q, k: hybrid_search.hybrid_search(q, k, 0.3)),\n    (\"Hybrid α=0.5\", lambda q, k: hybrid_search.hybrid_search(q, k, 0.5)),\n    (\"Hybrid α=0.7\", lambda q, k: hybrid_search.hybrid_search(q, k, 0.7))\n]\n\nscores = {}\nfor method_name, search_func in methods:\n    score = evaluator.evaluate(search_func, method_name, k=5)\n    scores[method_name] = score\n\n# Вывод лучшего метода\nbest_method = max(scores.items(), key=lambda x: x[1])\nprint(f\"\\n🎯 Лучший метод: {best_method[0]} с accuracy {best_method[1]:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T17:13:06.216371Z","iopub.execute_input":"2026-01-20T17:13:06.217260Z","iopub.status.idle":"2026-01-20T17:13:15.483999Z","shell.execute_reply.started":"2026-01-20T17:13:06.217220Z","shell.execute_reply":"2026-01-20T17:13:15.483226Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nУПРОЩЕННАЯ ОЦЕНКА КАЧЕСТВА:\n============================================================\n\nBM25 (Top-5):\n  Найдено релевантных: 14/204\n  Accuracy: 0.069\n\nDense (Top-5):\n  Найдено релевантных: 24/204\n  Accuracy: 0.118\n\nHybrid α=0.3 (Top-5):\n  Найдено релевантных: 14/204\n  Accuracy: 0.069\n\nHybrid α=0.5 (Top-5):\n  Найдено релевантных: 18/204\n  Accuracy: 0.088\n\nHybrid α=0.7 (Top-5):\n  Найдено релевантных: 20/204\n  Accuracy: 0.098\n\n🎯 Лучший метод: Dense с accuracy 0.118\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# 5. УПРОЩЕННАЯ ОЦЕНКА\nprint(\"\\n\" + \"=\"*60)\nprint(\"УПРОЩЕННАЯ ОЦЕНКА КАЧЕСТВА:\")\nprint(\"=\"*60)\n\n# Сначала проверим данные\nprint(\"Проверка данных questions.json...\")\nwith open(\"/kaggle/input/crunch/questions.json\", 'r') as f:\n    questions = json.load(f)\n\nprint(f\"Загружено вопросов: {len(questions)}\")\nprint(\"\\nПример первых 2 вопросов:\")\nfor i, q in enumerate(questions[:2]):\n    print(f\"  {i+1}. Вопрос: '{q.get('question', 'NO QUESTION')[:50]}...'\")\n    print(f\"     ID релевантных статей: {q.get('id', 'NO ID')}\")\n    print()\n\n# Создаем mapping\narticle_id_to_index = {}\nfor idx, article in enumerate(results[\"articles\"]):\n    article_id_to_index[article[\"id\"]] = idx\n\nprint(f\"Создан mapping для {len(article_id_to_index)} статей\")\nprint(f\"Пример ID статей: {list(article_id_to_index.keys())[:5]}\")\n\n# Проверим совпадение ID\nprint(\"\\nПроверка совпадения ID вопросов и статей...\")\nfor i, q in enumerate(questions[:3]):\n    relevant_ids = q.get('id', [])\n    if isinstance(relevant_ids, str):\n        relevant_ids = [relevant_ids]\n    \n    for rel_id in relevant_ids:\n        if rel_id in article_id_to_index:\n            print(f\"  ✓ Вопрос '{q.get('question', '')[:30]}...': ID {rel_id} найден в статьях\")\n        else:\n            print(f\"  ✗ Вопрос '{q.get('question', '')[:30]}...': ID {rel_id} НЕ найден в статьях\")\n\n# Создаем простой evaluator\nclass SimpleEvaluator:\n    def __init__(self, questions_path, article_id_to_index):\n        with open(questions_path, 'r') as f:\n            self.questions = json.load(f)\n        self.article_id_to_index = article_id_to_index\n    \n    def evaluate(self, search_function, method_name, top_k=5):\n        print(f\"\\n{'='*40}\")\n        print(f\"ТЕСТИРОВАНИЕ МЕТОДА: {method_name}\")\n        print(f\"{'='*40}\")\n        \n        total_correct = 0\n        total_possible = 0\n        \n        # Протестируем сначала на одном запросе с детальным выводом\n        test_query_data = self.questions[0] if self.questions else None\n        if test_query_data:\n            query = test_query_data.get(\"question\", \"\")\n            print(f\"\\nТестовый запрос: '{query}'\")\n            \n            # Получаем результаты поиска\n            try:\n                search_results = search_function(query, top_k=top_k)\n                print(f\"  Найдено результатов: {len(search_results)}\")\n                \n                if search_results:\n                    print(\"  Первые 3 результата:\")\n                    for i, result in enumerate(search_results[:3]):\n                        article_id = result[\"article\"][\"id\"]\n                        score = result.get(\"score\", result.get(\"hybrid_score\", 0))\n                        print(f\"    {i+1}. ID: {article_id}, Score: {score:.4f}, Title: {result['article']['title'][:50]}...\")\n                else:\n                    print(\"  ⚠ Результаты поиска пустые!\")\n                    # Попробуем debug, почему поиск не работает\n                    self._debug_search(search_function, query)\n                    \n            except Exception as e:\n                print(f\"  Ошибка при поиске: {e}\")\n                import traceback\n                traceback.print_exc()\n        \n        # Теперь оценим все вопросы\n        print(f\"\\nОценка на всех вопросах ({method_name}, Top-{top_k}):\")\n        \n        for query_idx, query_data in enumerate(self.questions):\n            query = query_data.get(\"question\", \"\")\n            # Внимание: у вас в JSON поле называется 'id', а не 'relevant_article_ids'\n            relevant_ids = query_data.get(\"id\", [])\n            \n            # Если это строка, делаем список\n            if isinstance(relevant_ids, str):\n                relevant_ids = [relevant_ids]\n            \n            if not relevant_ids:\n                # print(f\"  Вопрос {query_idx+1}: нет релевантных ID\")\n                continue\n            \n            try:\n                results = search_function(query, top_k=top_k)\n            except Exception as e:\n                # print(f\"  Вопрос {query_idx+1}: ошибка - {e}\")\n                continue\n            \n            # Считаем сколько релевантных нашли\n            found_relevant = 0\n            for result in results:\n                if result[\"article\"][\"id\"] in relevant_ids:\n                    found_relevant += 1\n            \n            total_correct += found_relevant\n            total_possible += min(len(relevant_ids), top_k)\n            \n            # if query_idx < 3:  # Показать первые 3 для debug\n            #     print(f\"  Вопрос {query_idx+1}: '{query[:30]}...'\")\n            #     print(f\"    Релевантные ID: {relevant_ids}\")\n            #     print(f\"    Найдено: {found_relevant}/{min(len(relevant_ids), top_k)}\")\n        \n        accuracy = total_correct / total_possible if total_possible > 0 else 0\n        print(f\"\\n  ИТОГО:\")\n        print(f\"    Найдено релевантных: {total_correct}/{total_possible}\")\n        print(f\"    Accuracy: {accuracy:.3f}\")\n        \n        return accuracy\n    \n    def _debug_search(self, search_function, query):\n        \"\"\"Debug функция для понимания, почему поиск не работает\"\"\"\n        print(\"\\n  DEBUG поиска:\")\n        \n        # Проверим, что это за функция\n        print(f\"    Тип search_function: {type(search_function)}\")\n        \n        # Проверим, доступен ли hybrid_search\n        try:\n            # Если это лямбда, попробуем проверить ее работу\n            import inspect\n            print(f\"    Сигнатура: {inspect.signature(search_function)}\")\n        except:\n            pass\n\n# Инициализация поиска\nprint(\"\\n\" + \"=\"*60)\nprint(\"ИНИЦИАЛИЗАЦИЯ ПОИСКА\")\nprint(\"=\"*60)\n\nsearch_data = {\n    \"articles\": results[\"articles\"],\n    \"bm25_matrix\": results[\"bm25_matrix\"],\n    \"dense_embeddings\": results[\"dense_embeddings\"],\n    \"vocabulary\": results[\"vocabulary\"],\n    \"bm25_vectorizer_info\": results.get(\"bm25_vectorizer_info\", {})\n}\n\nprint(f\"Статей в search_data: {len(search_data['articles'])}\")\nprint(f\"BM25 матрица shape: {search_data['bm25_matrix'].shape}\")\nprint(f\"Dense эмбеддинги shape: {search_data['dense_embeddings'].shape}\")\n\nhybrid_search = HybridSearch(search_data)\nprint(f\"✓ HybridSearch инициализирован\")\nprint(f\"  has_dense: {hybrid_search.has_dense}\")\n\n# Сначала протестируем поиск вручную на тестовых запросах\nprint(\"\\n\" + \"=\"*60)\nprint(\"ТЕСТОВЫЕ ЗАПРОСЫ ВРУЧНУЮ\")\nprint(\"=\"*60)\n\ntest_queries = [\n    \"Google AI medical queries\",\n    \"Indonesia blocks chatbot\",\n    \"deepfake regulations\"\n]\n\nfor query in test_queries:\n    print(f\"\\nЗапрос: '{query}'\")\n    \n    # BM25 поиск\n    try:\n        bm25_results = hybrid_search.search_by_bm25(query, top_k=3)\n        print(f\"  BM25: найдено {len(bm25_results)} результатов\")\n        if bm25_results:\n            for i, r in enumerate(bm25_results[:2]):\n                print(f\"    {i+1}. {r['article']['title'][:50]}... (score: {r['score']:.4f})\")\n    except Exception as e:\n        print(f\"  BM25 ошибка: {e}\")\n    \n    # Dense поиск\n    if hybrid_search.has_dense:\n        try:\n            dense_results = hybrid_search.search_by_dense(query, top_k=3)\n            print(f\"  Dense: найдено {len(dense_results)} результатов\")\n            if dense_results:\n                for i, r in enumerate(dense_results[:2]):\n                    print(f\"    {i+1}. {r['article']['title'][:50]}... (score: {r['score']:.4f})\")\n        except Exception as e:\n            print(f\"  Dense ошибка: {e}\")\n\n# Теперь оценка\nevaluator = SimpleEvaluator(\"/kaggle/input/crunch/questions.json\", article_id_to_index)\n\n# Определяем методы поиска\ndef bm25_search(query, k):\n    return hybrid_search.search_by_bm25(query, top_k=k)\n\ndef dense_search(query, k):\n    return hybrid_search.search_by_dense(query, top_k=k)\n\ndef hybrid_search_alpha_03(query, k):\n    return hybrid_search.hybrid_search(query, top_k=k, alpha=0.3)\n\ndef hybrid_search_alpha_05(query, k):\n    return hybrid_search.hybrid_search(query, top_k=k, alpha=0.5)\n\ndef hybrid_search_alpha_07(query, k):\n    return hybrid_search.hybrid_search(query, top_k=k, alpha=0.7)\n\nmethods = [\n    (\"BM25\", bm25_search),\n    (\"Dense\", dense_search),\n    (\"Hybrid α=0.3\", hybrid_search_alpha_03),\n    (\"Hybrid α=0.5\", hybrid_search_alpha_05),\n    (\"Hybrid α=0.7\", hybrid_search_alpha_07)\n]\n\nscores = {}\nfor method_name, search_func in methods:\n    score = evaluator.evaluate(search_func, method_name, top_k=5)\n    scores[method_name] = score\n\n# Вывод лучшего метода\nif scores:\n    best_method = max(scores.items(), key=lambda x: x[1])\n    print(f\"\\n🎯 Лучший метод: {best_method[0]} с accuracy {best_method[1]:.3f}\")\nelse:\n    print(\"\\n⚠ Не удалось оценить ни один метод!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T17:00:54.597158Z","iopub.execute_input":"2026-01-20T17:00:54.597862Z","iopub.status.idle":"2026-01-20T17:00:55.644121Z","shell.execute_reply.started":"2026-01-20T17:00:54.597824Z","shell.execute_reply":"2026-01-20T17:00:55.642648Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nУПРОЩЕННАЯ ОЦЕНКА КАЧЕСТВА:\n============================================================\nПроверка данных questions.json...\nЗагружено вопросов: 55\n\nПример первых 2 вопросов:\n  1. Вопрос: 'How are tech giants addressing the issue of AI hal...'\n     ID релевантных статей: ['0821507d-107b-526d-a4e6-03c7ffb90318', '507593c7-dd09-5647-8d9c-2cedb1ca3226', '6095f86a-b1b8-5b27-aafe-760252116ae1']\n\n  2. Вопрос: 'What is the strategic importance of Physical AI an...'\n     ID релевантных статей: ['81ab4cfd-cb69-56b5-a0a7-ca08218a7117', '57c9e8b1-1d91-5d22-af7f-9a64fa0548e6', '87179b33-ad32-5122-a0cc-41ed46ab011c']\n\nСоздан mapping для 5488 статей\nПример ID статей: ['0821507d-107b-526d-a4e6-03c7ffb90318', '0dcd2040-b0b6-5f1a-bbf5-44d36b181391', 'cb570756-1aa7-5602-8651-7ff6f00a6952', '1aecd534-13a9-597f-b5ec-cc79ae6ba8e9', '81ab4cfd-cb69-56b5-a0a7-ca08218a7117']\n\nПроверка совпадения ID вопросов и статей...\n  ✓ Вопрос 'How are tech giants addressing...': ID 0821507d-107b-526d-a4e6-03c7ffb90318 найден в статьях\n  ✓ Вопрос 'How are tech giants addressing...': ID 507593c7-dd09-5647-8d9c-2cedb1ca3226 найден в статьях\n  ✓ Вопрос 'How are tech giants addressing...': ID 6095f86a-b1b8-5b27-aafe-760252116ae1 найден в статьях\n  ✓ Вопрос 'What is the strategic importan...': ID 81ab4cfd-cb69-56b5-a0a7-ca08218a7117 найден в статьях\n  ✓ Вопрос 'What is the strategic importan...': ID 57c9e8b1-1d91-5d22-af7f-9a64fa0548e6 найден в статьях\n  ✓ Вопрос 'What is the strategic importan...': ID 87179b33-ad32-5122-a0cc-41ed46ab011c найден в статьях\n  ✓ Вопрос 'How are data ownership rules e...': ID 1aecd534-13a9-597f-b5ec-cc79ae6ba8e9 найден в статьях\n  ✗ Вопрос 'How are data ownership rules e...': ID 3e70d4c9-b68a-5793-9c86-1d13f993d091 НЕ найден в статьях\n  ✗ Вопрос 'How are data ownership rules e...': ID 29624515-9430-589b-9679-05249f3e0988 НЕ найден в статьях\n\n============================================================\nИНИЦИАЛИЗАЦИЯ ПОИСКА\n============================================================\nСтатей в search_data: 5488\nBM25 матрица shape: (5488, 50000)\nDense эмбеддинги shape: (5488, 384)\n✓ HybridSearch инициализирован\n  has_dense: True\n\n============================================================\nТЕСТОВЫЕ ЗАПРОСЫ ВРУЧНУЮ\n============================================================\n\nЗапрос: 'Google AI medical queries'\n  BM25: найдено 3 результатов\n    1. Meta has found another way to keep you engaged: Ch... (score: 0.6662)\n    2. Meta starts testing user-created AI chatbots on In... (score: 0.6561)\n  Dense: найдено 3 результатов\n    1. Google launches new healthcare-related features fo... (score: 0.6019)\n    2. Hugging Face releases a benchmark for testing gene... (score: 0.5966)\n\nЗапрос: 'Indonesia blocks chatbot'\n  BM25: найдено 3 результатов\n    1. After India, OpenAI launches its affordable ChatGP... (score: 1.2880)\n    2. Google’s cheaper AI Plus plan is now available in ... (score: 0.9763)\n  Dense: найдено 3 результатов\n    1. Indonesia and Malaysia block Grok over non-consens... (score: 0.5274)\n    2. ChatGPT suffered a major outage this morning, but ... (score: 0.4608)\n\nЗапрос: 'deepfake regulations'\n  BM25: найдено 3 результатов\n    1. TechCrunch Minute: YouTube makes it easier to repo... (score: 0.5542)\n    2. UK confirms plans to criminalize the creation of s... (score: 0.5339)\n  Dense: найдено 3 результатов\n    1. Hundreds of AI luminaries sign letter calling for ... (score: 0.5261)\n    2. UK confirms plans to criminalize the creation of s... (score: 0.4724)\n\n========================================\nТЕСТИРОВАНИЕ МЕТОДА: BM25\n========================================\n\nТестовый запрос: 'How are tech giants addressing the issue of AI hallucinations and misinformation in medical and critical health-related search queries?'\n  Ошибка при поиске: bm25_search() got an unexpected keyword argument 'top_k'\n\nОценка на всех вопросах (BM25, Top-5):\n\n  ИТОГО:\n    Найдено релевантных: 0/0\n    Accuracy: 0.000\n\n========================================\nТЕСТИРОВАНИЕ МЕТОДА: Dense\n========================================\n\nТестовый запрос: 'How are tech giants addressing the issue of AI hallucinations and misinformation in medical and critical health-related search queries?'\n  Ошибка при поиске: dense_search() got an unexpected keyword argument 'top_k'\n\nОценка на всех вопросах (Dense, Top-5):\n\n  ИТОГО:\n    Найдено релевантных: 0/0\n    Accuracy: 0.000\n\n========================================\nТЕСТИРОВАНИЕ МЕТОДА: Hybrid α=0.3\n========================================\n\nТестовый запрос: 'How are tech giants addressing the issue of AI hallucinations and misinformation in medical and critical health-related search queries?'\n  Ошибка при поиске: hybrid_search_alpha_03() got an unexpected keyword argument 'top_k'\n\nОценка на всех вопросах (Hybrid α=0.3, Top-5):\n\n  ИТОГО:\n    Найдено релевантных: 0/0\n    Accuracy: 0.000\n\n========================================\nТЕСТИРОВАНИЕ МЕТОДА: Hybrid α=0.5\n========================================\n\nТестовый запрос: 'How are tech giants addressing the issue of AI hallucinations and misinformation in medical and critical health-related search queries?'\n  Ошибка при поиске: hybrid_search_alpha_05() got an unexpected keyword argument 'top_k'\n\nОценка на всех вопросах (Hybrid α=0.5, Top-5):\n\n  ИТОГО:\n    Найдено релевантных: 0/0\n    Accuracy: 0.000\n\n========================================\nТЕСТИРОВАНИЕ МЕТОДА: Hybrid α=0.7\n========================================\n\nТестовый запрос: 'How are tech giants addressing the issue of AI hallucinations and misinformation in medical and critical health-related search queries?'\n  Ошибка при поиске: hybrid_search_alpha_07() got an unexpected keyword argument 'top_k'\n\nОценка на всех вопросах (Hybrid α=0.7, Top-5):\n\n  ИТОГО:\n    Найдено релевантных: 0/0\n    Accuracy: 0.000\n\n🎯 Лучший метод: BM25 с accuracy 0.000\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_55/1194900496.py\", line 62, in evaluate\n    search_results = search_function(query, top_k=top_k)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: bm25_search() got an unexpected keyword argument 'top_k'\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_55/1194900496.py\", line 62, in evaluate\n    search_results = search_function(query, top_k=top_k)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: dense_search() got an unexpected keyword argument 'top_k'\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_55/1194900496.py\", line 62, in evaluate\n    search_results = search_function(query, top_k=top_k)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: hybrid_search_alpha_03() got an unexpected keyword argument 'top_k'\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_55/1194900496.py\", line 62, in evaluate\n    search_results = search_function(query, top_k=top_k)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: hybrid_search_alpha_05() got an unexpected keyword argument 'top_k'\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_55/1194900496.py\", line 62, in evaluate\n    search_results = search_function(query, top_k=top_k)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: hybrid_search_alpha_07() got an unexpected keyword argument 'top_k'\n","output_type":"stream"}],"execution_count":13}]}